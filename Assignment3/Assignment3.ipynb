{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "08ee7c96b7c64f3c9798670c1a953287": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6404f712d19946d5ba2ccc3b2dd8f822",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fd825a8459354b07b6792e59a189cf75",
              "IPY_MODEL_4bf9f3243f0948d88b53ab16fd4ccce1"
            ]
          }
        },
        "6404f712d19946d5ba2ccc3b2dd8f822": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fd825a8459354b07b6792e59a189cf75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_819eb24354434ab3b2e8bc1912e70a91",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5.06MB of 5.06MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bc834e1d39cf4975be045ae3099166bc"
          }
        },
        "4bf9f3243f0948d88b53ab16fd4ccce1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5290330c875a43519e016b2fe9fc9ae7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8e575780ff08472ea553a8aa633c94d2"
          }
        },
        "819eb24354434ab3b2e8bc1912e70a91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bc834e1d39cf4975be045ae3099166bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5290330c875a43519e016b2fe9fc9ae7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8e575780ff08472ea553a8aa633c94d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Swathi1309/ED18B034_ME18B133_CS6910/blob/main/Assignment3/Assignment3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppVny72Q-SPg"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from keras import Model\n",
        "from keras.layers import SimpleRNN, LSTM, GRU, Dense, Dropout\n",
        "import tarfile"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vV6TzDuChLd8",
        "outputId": "061cbf5d-34f8-456a-eb3b-d3b5b8d431ca"
      },
      "source": [
        "!pip install wandb\n",
        "!wandb login\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "wandb.init(project=\"CS6910-assg3\", entity=\"narendv\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wandb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/ee/d755f9e5466df64c8416a2c6a860fb3aaa43ed6ea8e8e8e81460fda5788b/wandb-0.10.28-py2.py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 8.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Collecting GitPython>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/99/98019716955ba243657daedd1de8f3a88ca1f5b75057c38e959db22fb87b/GitPython-3.1.14-py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 38.0MB/s \n",
            "\u001b[?25hCollecting sentry-sdk>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/92/5a33be64990ba815364a8f2dd9e6f51de60d23dfddafb4f1fc5577d4dc64/sentry_sdk-1.0.0-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 22.8MB/s \n",
            "\u001b[?25hCollecting subprocess32>=3.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 12.7MB/s \n",
            "\u001b[?25hCollecting pathtools\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/fd/01/ff260a18caaf4457eb028c96eeb405c4a230ca06c8ec9c1379f813caa52e/configparser-5.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.12.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.0->wandb) (56.0.0)\n",
            "Collecting smmap<5,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: subprocess32, pathtools\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp37-none-any.whl size=6489 sha256=f5c2df0ea2fc0ac02d7098911648696d3b770deabb88c88c2326c70d67bdd579\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp37-none-any.whl size=8786 sha256=ee108476772ea33222a9150ef3d77adfeb3d3d1feed166c88cf9e2fdc4e3b8f2\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "Successfully built subprocess32 pathtools\n",
            "Installing collected packages: shortuuid, smmap, gitdb, GitPython, sentry-sdk, subprocess32, pathtools, docker-pycreds, configparser, wandb\n",
            "Successfully installed GitPython-3.1.14 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.7 pathtools-0.1.2 sentry-sdk-1.0.0 shortuuid-1.0.1 smmap-4.0.0 subprocess32-3.5.4 wandb-0.10.28\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnarendv\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.28<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">zany-dust-26</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/narendv/CS6910-assg3\" target=\"_blank\">https://wandb.ai/narendv/CS6910-assg3</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/narendv/CS6910-assg3/runs/3tjgs9zm\" target=\"_blank\">https://wandb.ai/narendv/CS6910-assg3/runs/3tjgs9zm</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210430_161323-3tjgs9zm</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f93eb096c50>"
            ],
            "text/html": [
              "<h1>Run(3tjgs9zm)</h1><iframe src=\"https://wandb.ai/narendv/CS6910-assg3/runs/3tjgs9zm\" style=\"border:none;width:100%;height:400px\"></iframe>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d2LNP-C3PD6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc9b5720-ab48-4309-9c0d-1e165bb5eb54"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcMrqAD0GVTJ"
      },
      "source": [
        "Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CV1gW8TTyr7x"
      },
      "source": [
        "\n",
        "my_tar = tarfile.open('/content/drive/MyDrive/Dakshina dataset/dakshina_dataset_v1.0.tar')\n",
        "my_tar.extractall('/content/drive/MyDrive/Dakshina dataset') # specify which folder to extract to\n",
        "my_tar.close()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Pn0kolbGcbE"
      },
      "source": [
        "Examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDYd7sMK4s8_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07b0db64-6d27-4aff-b2d9-c73b0920e3eb"
      },
      "source": [
        "import csv\n",
        "hi_to_eng = open(\"/content/drive/MyDrive/Dakshina dataset/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv\")\n",
        "read_tsv = csv.reader(hi_to_eng, delimiter=\"\\t\")\n",
        "i=0\n",
        "for row in read_tsv:\n",
        "  i +=1\n",
        "  print(row)\n",
        "  if i==5:\n",
        "    break\n",
        "hi_to_eng.close()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['अं', 'an', '3']\n",
            "['अंकगणित', 'ankganit', '3']\n",
            "['अंकल', 'uncle', '4']\n",
            "['अंकुर', 'ankur', '4']\n",
            "['अंकुरण', 'ankuran', '3']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ap4sT1mhcnJ"
      },
      "source": [
        "  # Number of samples to train on.\n",
        "# Path to the data txt file on disk.\n",
        "data_path_train = \"/content/drive/MyDrive/Dakshina dataset/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv\"\n",
        "data_path_dev = '/content/drive/MyDrive/Dakshina dataset/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.dev.tsv'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoMs0KpchYxh"
      },
      "source": [
        "def load_inputs(data_path,data):\n",
        "  # Vectorize the data.\n",
        "  input_texts = []\n",
        "  target_texts = []\n",
        "  input_characters = set()\n",
        "  target_characters = set()\n",
        "  with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
        "      lines = f.read().split(\"\\n\")\n",
        "  for line in lines[: (len(lines) - 1)]:\n",
        "      input_text, target_text, _ = line.split(\"\\t\")\n",
        "      # We use \"tab\" as the \"start sequence\" character\n",
        "      # for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "      target_text = \"\\t\" + target_text + \"\\n\"\n",
        "      input_texts.append(input_text)\n",
        "      target_texts.append(target_text)\n",
        "      for char in input_text:\n",
        "          if char not in input_characters:\n",
        "              input_characters.add(char)\n",
        "      for char in target_text:\n",
        "          if char not in target_characters:\n",
        "              target_characters.add(char)\n",
        "\n",
        "  input_characters = sorted(list(input_characters))\n",
        "  target_characters = sorted(list(target_characters))\n",
        "  num_encoder_tokens = len(input_characters)\n",
        "  num_decoder_tokens = len(target_characters)\n",
        "  max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "  max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "\n",
        "  # print(\"Number of samples:\", len(input_texts))\n",
        "  # print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
        "  # print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
        "  # print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
        "  # print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n",
        "\n",
        "  input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
        "  target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
        "  if data == 'train':\n",
        "    encoder_input_data = np.zeros(\n",
        "        (len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\"\n",
        "    )\n",
        "    decoder_input_data = np.zeros(\n",
        "        (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
        "    )\n",
        "    decoder_target_data = np.zeros(\n",
        "        (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
        "    )\n",
        "  if data == 'dev':\n",
        "    encoder_input_data = np.zeros(\n",
        "        (len(input_texts), max_encoder_seq_length, input_token_train), dtype=\"float32\"\n",
        "    )\n",
        "    decoder_input_data = np.zeros(\n",
        "        (len(input_texts), max_decoder_seq_length, output_token_train), dtype=\"float32\"\n",
        "    )\n",
        "    decoder_target_data = np.zeros(\n",
        "        (len(input_texts), max_decoder_seq_length, output_token_train), dtype=\"float32\"\n",
        "    )\n",
        "  \n",
        "\n",
        "  for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "      for t, char in enumerate(input_text):\n",
        "          encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
        "      # encoder_input_data[i, (t + 1):, input_token_index[\" \"]] = 1.0\n",
        "      for t, char in enumerate(target_text):\n",
        "          # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "          decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
        "          if t > 0:\n",
        "              # decoder_target_data will be ahead by one timestep\n",
        "              # and will not include the start character.\n",
        "              decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
        "      # decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n",
        "      # decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0\n",
        "\n",
        "  return encoder_input_data, decoder_input_data, decoder_target_data, num_encoder_tokens, num_decoder_tokens"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q83Qb1QcASDh"
      },
      "source": [
        "global enc_input_train, dec_input_train, dec_target_train, input_token_train, output_token_train\n",
        "global enc_input_dev, dec_input_dev, dec_target_dev\n",
        "enc_input_train, dec_input_train, dec_target_train, input_token_train, output_token_train = load_inputs(data_path_train,'train')\n",
        "enc_input_dev, dec_input_dev, dec_target_dev, _, _ = load_inputs(data_path_dev,'dev')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJHFjZGFxpCb"
      },
      "source": [
        "def encoder(X_input_enc,in_token_no,enc_block, latent_dim):\n",
        "  \n",
        "  if enc_block =='LSTM':\n",
        "    enc_out ,h ,c = LSTM(latent_dim, return_state=True)(X_input_enc)\n",
        "    s = [h,c]\n",
        "  elif enc_block =='GRU':\n",
        "    enc_out ,s = GRU(latent_dim, return_state=True)(X_input_enc)\n",
        "  else:\n",
        "    enc_out ,s = SimpleRNN(latent_dim, return_state=True)(X_input_enc)\n",
        "  \n",
        "  return enc_out,s\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tgqA46f6gtJ"
      },
      "source": [
        "def decoder(X_input_dec, hs_init, latent_dim, out_token_no, dec_block,dense_no,drop_no):\n",
        "  \n",
        "\n",
        "  if dec_block == 'LSTM':\n",
        "    out_dec, _, _ = LSTM(latent_dim, return_sequences=True, return_state=True)(X_input_dec, initial_state = hs_init)\n",
        "  elif dec_block == 'GRU':\n",
        "    out_dec, _ = GRU(latent_dim, return_sequences=True, return_state=True)(X_input_dec, initial_state = hs_init)\n",
        "  else:\n",
        "    out_dec, _ = SimpleRNN(latent_dim, return_sequences=True, return_state=True)(X_input_dec, initial_state = hs_init)\n",
        "  \n",
        "  out_dec = Dense(dense_no, activation='tanh')(out_dec)\n",
        "  out_dec = Dropout(drop_no)(out_dec)\n",
        "  out_dec = Dense(out_token_no, activation=\"softmax\")(out_dec)\n",
        "\n",
        "  return out_dec"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAWVP3PL8kdB"
      },
      "source": [
        "def RNN_model(in_token_no, enc_block, latent_dim, out_token_no, dec_block,dense_no,drop_no):\n",
        "  X_input_enc = keras.Input(shape=(None, in_token_no))\n",
        "  X_input_dec = keras.Input(shape=(None, out_token_no))\n",
        "  _,s_init = encoder(X_input_enc,in_token_no,enc_block,latent_dim)\n",
        "  out_dec = decoder(X_input_dec,s_init,latent_dim, out_token_no, dec_block, dense_no,drop_no)\n",
        "  model = Model(inputs = [X_input_enc,X_input_dec], outputs = out_dec)\n",
        "\n",
        "  return model"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_8eeDMhed_v"
      },
      "source": [
        "lat_dim=256\n",
        "model = RNN_model(input_token_train,'RNN',lat_dim,output_token_train,'RNN', 64,0)\n",
        "# keras.utils.plot_model(model,show_shapes=True)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oquP5kRhmm8H"
      },
      "source": [
        "def enc_inference(model):\n",
        "  X_in_enc = model.input[0]\n",
        "  enc_out ,h ,s = model.layers[2].output\n",
        "  X_out_enc = [h,s]\n",
        "  enc_model = keras.Model(inputs = X_in_enc, outputs = X_out_enc)\n",
        "\n",
        "  return enc_model\n",
        "\n",
        "def dec_inference(model):\n",
        "  dec_inputs = model.input[1]\n",
        "  dec_input_h = keras.Input(shape=(latent_dim,))\n",
        "  dec_input_s = keras.Input(shape=(latent_dim,))\n",
        "  hs_inputs = [dec_input_h,dec_input_s]\n",
        "  dec_model = model.layers[3]\n",
        "  dec_outputs, h_dec, s_dec = dec_model(dec_inputs, initial_state=hs_inputs)\n",
        "  hs_outputs = [h_dec, s_dec]\n",
        "  dec_dense = model.layers[4]\n",
        "  dec_outputs = dec_dense(dec_outputs)\n",
        "  dec_model = keras.Model(inputs = [dec_inputs] + hs_inputs, outputs = [decoder_outputs]\n",
        "                              + hs_outputs)\n",
        "  \n",
        "  return dec_model\n",
        "\n",
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0, target_token_index[\"\\t\"]] = 1.0\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = \"\"\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_seq_length:\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.0\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "    return decoded_sentence"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "ZUPZBlssPUtq",
        "outputId": "f797fe94-ff40-4709-e74c-df2e36e544d4"
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss = 'categorical_crossentropy', metrics='accuracy')\n",
        "model.fit([enc_input_train,dec_input_train], dec_target_train,\n",
        "          batch_size = 256,epochs=20, validation_data=([enc_input_dev,dec_input_dev], dec_target_dev))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "40/40 [==============================] - 4s 58ms/step - loss: 1.1952 - accuracy: 0.0893 - val_loss: 1.2119 - val_accuracy: 0.0626\n",
            "Epoch 2/20\n",
            "40/40 [==============================] - 2s 48ms/step - loss: 1.0218 - accuracy: 0.1208 - val_loss: 1.2553 - val_accuracy: 0.0541\n",
            "Epoch 3/20\n",
            "29/40 [====================>.........] - ETA: 0s - loss: 1.0326 - accuracy: 0.1196"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-646de9e55332>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rmsprop'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m model.fit([enc_input_train,dec_input_train], dec_target_train,\n\u001b[0;32m----> 3\u001b[0;31m           batch_size = 256,epochs=20, validation_data=([enc_input_dev,dec_input_dev], dec_target_dev))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/integration/keras/keras.py\u001b[0m in \u001b[0;36mnew_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcbk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcbks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0mset_wandb_attrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mold_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0mtraining_arrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_fit_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOgRw2Vb7FlA"
      },
      "source": [
        "import pprint"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oq0DRwp1W7_f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "508b598b-dd74-4778-a8b8-14ad48a106b2"
      },
      "source": [
        "sweep_config = {\n",
        "    'method': 'grid'\n",
        "    }\n",
        "\n",
        "parameters_dict = {\n",
        "    'encoder_block':{\n",
        "        'values': ['LSTM']\n",
        "      },\n",
        "    # 'encoder_layers': {\n",
        "    #     'values': [1,2,3]\n",
        "    #   },\n",
        "    'decoder_block':{\n",
        "      'values' : ['LSTM']\n",
        "      },\n",
        "    # 'decoder_layers': {\n",
        "    #     'values': [1,2,3]\n",
        "    #   },\n",
        "    'latent_dimension': {\n",
        "        'values': [256]\n",
        "      },\n",
        "    'hidden_layer': {\n",
        "        'values': [128]\n",
        "      },\n",
        "    'dropout': {\n",
        "        'values': [0]\n",
        "      },\n",
        "    'epochs' : {\n",
        "        'values' : [60]\n",
        "    }\n",
        "}\n",
        "\n",
        "sweep_config['parameters'] = parameters_dict\n",
        "pprint.pprint(sweep_config)\n",
        "\n",
        "def training_sweep(config=None):\n",
        "    with wandb.init(config=config):\n",
        "        print(input_token_train)\n",
        "        config = wandb.config\n",
        "        print(output_token_train)\n",
        "        model = RNN_model(input_token_train, config.encoder_block, config.latent_dimension, output_token_train, config.decoder_block,  config.hidden_layer, config.dropout)\n",
        "        print('lol')\n",
        "        model.compile(optimizer='rmsprop', loss = 'categorical_crossentropy', metrics='accuracy')\n",
        "        print('lol')\n",
        "        history = model.fit([enc_input_train,dec_input_train], dec_target_train, \n",
        "                            epochs=config.epochs,\n",
        "                            validation_data = ([enc_input_dev,dec_input_dev], dec_target_dev),\n",
        "                            callbacks = [WandbCallback()]\n",
        "                            )\n",
        "        print('lol')\n",
        "        # name = str(config.encoder_block) + '_' + str(config.encoder_layers) + '_' + str(config.decoder_block) + '_' + str(config.decoder_layers) + '_' + str(config.hidden_layer) + '_' + str(config.dropout) + '_' + str(config.epochs)\n",
        "        # location = '/content/drive/MyDrive/Transliteration/' + name\n",
        "        # model.save(location)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'method': 'grid',\n",
            " 'parameters': {'decoder_block': {'values': ['LSTM']},\n",
            "                'dropout': {'values': [0]},\n",
            "                'encoder_block': {'values': ['LSTM']},\n",
            "                'epochs': {'values': [60]},\n",
            "                'hidden_layer': {'values': [128]},\n",
            "                'latent_dimension': {'values': [256]}}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1shGb7ZrJqH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "08ee7c96b7c64f3c9798670c1a953287",
            "6404f712d19946d5ba2ccc3b2dd8f822",
            "fd825a8459354b07b6792e59a189cf75",
            "4bf9f3243f0948d88b53ab16fd4ccce1",
            "819eb24354434ab3b2e8bc1912e70a91",
            "bc834e1d39cf4975be045ae3099166bc",
            "5290330c875a43519e016b2fe9fc9ae7",
            "8e575780ff08472ea553a8aa633c94d2"
          ]
        },
        "outputId": "3e31ab26-78ee-4955-f4e4-eb1601dde283"
      },
      "source": [
        "sweep_id = wandb.sweep(sweep_config, project=\"CS6910-assg3\")\n",
        "wandb.agent(sweep_id, training_sweep)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Create sweep with ID: bes2wpdh\n",
            "Sweep URL: https://wandb.ai/narendv/CS6910-assg3/sweeps/bes2wpdh\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: h4d1mleg with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_block: LSTM\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_block: LSTM\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 60\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlatent_dimension: 256\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.28<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">stoic-sweep-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/narendv/CS6910-assg3\" target=\"_blank\">https://wandb.ai/narendv/CS6910-assg3</a><br/>\n",
              "                Sweep page: <a href=\"https://wandb.ai/narendv/CS6910-assg3/sweeps/bes2wpdh\" target=\"_blank\">https://wandb.ai/narendv/CS6910-assg3/sweeps/bes2wpdh</a><br/>\n",
              "Run page: <a href=\"https://wandb.ai/narendv/CS6910-assg3/runs/h4d1mleg\" target=\"_blank\">https://wandb.ai/narendv/CS6910-assg3/runs/h4d1mleg</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210430_175948-h4d1mleg</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "63\n",
            "28\n",
            "lol\n",
            "lol\n",
            "Epoch 1/60\n",
            "1382/1382 [==============================] - 16s 9ms/step - loss: 0.9539 - accuracy: 0.1051 - val_loss: 1.1106 - val_accuracy: 0.1125\n",
            "Epoch 2/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.5539 - accuracy: 0.2062 - val_loss: 1.4016 - val_accuracy: 0.0769\n",
            "Epoch 3/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.3737 - accuracy: 0.2605 - val_loss: 1.5165 - val_accuracy: 0.0789\n",
            "Epoch 4/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.2665 - accuracy: 0.2919 - val_loss: 1.5546 - val_accuracy: 0.0883\n",
            "Epoch 5/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.2093 - accuracy: 0.3084 - val_loss: 1.5771 - val_accuracy: 0.0901\n",
            "Epoch 6/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.1765 - accuracy: 0.3188 - val_loss: 1.5795 - val_accuracy: 0.0923\n",
            "Epoch 7/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.1558 - accuracy: 0.3239 - val_loss: 1.6227 - val_accuracy: 0.0922\n",
            "Epoch 8/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.1409 - accuracy: 0.3282 - val_loss: 1.6339 - val_accuracy: 0.0921\n",
            "Epoch 9/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.1288 - accuracy: 0.3299 - val_loss: 1.6428 - val_accuracy: 0.0945\n",
            "Epoch 10/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.1204 - accuracy: 0.3326 - val_loss: 1.6104 - val_accuracy: 0.0990\n",
            "Epoch 11/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.1134 - accuracy: 0.3347 - val_loss: 1.6490 - val_accuracy: 0.0964\n",
            "Epoch 12/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.1077 - accuracy: 0.3368 - val_loss: 1.6646 - val_accuracy: 0.0973\n",
            "Epoch 13/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.1026 - accuracy: 0.3379 - val_loss: 1.6554 - val_accuracy: 0.0971\n",
            "Epoch 14/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.0992 - accuracy: 0.3388 - val_loss: 1.6904 - val_accuracy: 0.0989\n",
            "Epoch 15/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.0945 - accuracy: 0.3405 - val_loss: 1.7028 - val_accuracy: 0.0988\n",
            "Epoch 16/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.0913 - accuracy: 0.3405 - val_loss: 1.7197 - val_accuracy: 0.0946\n",
            "Epoch 17/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.0883 - accuracy: 0.3409 - val_loss: 1.7421 - val_accuracy: 0.0944\n",
            "Epoch 18/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.0863 - accuracy: 0.3421 - val_loss: 1.7201 - val_accuracy: 0.0956\n",
            "Epoch 19/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.0836 - accuracy: 0.3418 - val_loss: 1.7045 - val_accuracy: 0.0971\n",
            "Epoch 20/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.0822 - accuracy: 0.3426 - val_loss: 1.7664 - val_accuracy: 0.0948\n",
            "Epoch 21/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.0818 - accuracy: 0.3428 - val_loss: 1.7095 - val_accuracy: 0.0981\n",
            "Epoch 22/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.0797 - accuracy: 0.3432 - val_loss: 1.7442 - val_accuracy: 0.0958\n",
            "Epoch 23/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.0790 - accuracy: 0.3430 - val_loss: 1.7101 - val_accuracy: 0.0974\n",
            "Epoch 24/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.0794 - accuracy: 0.3430 - val_loss: 1.7792 - val_accuracy: 0.0945\n",
            "Epoch 25/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.0785 - accuracy: 0.3434 - val_loss: 1.7446 - val_accuracy: 0.0978\n",
            "Epoch 26/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.0778 - accuracy: 0.3438 - val_loss: 1.7472 - val_accuracy: 0.0964\n",
            "Epoch 27/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.0779 - accuracy: 0.3446 - val_loss: 1.7436 - val_accuracy: 0.0974\n",
            "Epoch 28/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.0778 - accuracy: 0.3432 - val_loss: 1.7125 - val_accuracy: 0.0980\n",
            "Epoch 29/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.0776 - accuracy: 0.3448 - val_loss: 1.7587 - val_accuracy: 0.0971\n",
            "Epoch 30/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.0776 - accuracy: 0.3431 - val_loss: 1.7436 - val_accuracy: 0.0957\n",
            "Epoch 31/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.0785 - accuracy: 0.3446 - val_loss: 1.7601 - val_accuracy: 0.0939\n",
            "Epoch 32/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.0789 - accuracy: 0.3438 - val_loss: 1.7746 - val_accuracy: 0.0935\n",
            "Epoch 33/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.0795 - accuracy: 0.3440 - val_loss: 1.7532 - val_accuracy: 0.0930\n",
            "Epoch 34/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.0789 - accuracy: 0.3444 - val_loss: 1.7727 - val_accuracy: 0.0954\n",
            "Epoch 35/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.0803 - accuracy: 0.3435 - val_loss: 1.7520 - val_accuracy: 0.0939\n",
            "Epoch 36/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.0816 - accuracy: 0.3434 - val_loss: 1.7557 - val_accuracy: 0.0928\n",
            "Epoch 37/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.0826 - accuracy: 0.3428 - val_loss: 1.7514 - val_accuracy: 0.0943\n",
            "Epoch 38/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.0821 - accuracy: 0.3434 - val_loss: 1.7645 - val_accuracy: 0.0925\n",
            "Epoch 39/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.0839 - accuracy: 0.3429 - val_loss: 1.7713 - val_accuracy: 0.0920\n",
            "Epoch 40/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.0845 - accuracy: 0.3429 - val_loss: 1.7415 - val_accuracy: 0.0907\n",
            "Epoch 41/60\n",
            "1382/1382 [==============================] - 11s 8ms/step - loss: 0.0856 - accuracy: 0.3423 - val_loss: 1.7495 - val_accuracy: 0.0926\n",
            "Epoch 42/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.0864 - accuracy: 0.3414 - val_loss: 1.7755 - val_accuracy: 0.0905\n",
            "Epoch 43/60\n",
            "1382/1382 [==============================] - 12s 8ms/step - loss: 0.0870 - accuracy: 0.3430 - val_loss: 1.7543 - val_accuracy: 0.0915\n",
            "Epoch 44/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.0884 - accuracy: 0.3426 - val_loss: 1.7395 - val_accuracy: 0.0931\n",
            "Epoch 45/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.0886 - accuracy: 0.3419 - val_loss: 1.7339 - val_accuracy: 0.0910\n",
            "Epoch 46/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.0900 - accuracy: 0.3417 - val_loss: 1.7129 - val_accuracy: 0.0935\n",
            "Epoch 47/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.0911 - accuracy: 0.3410 - val_loss: 1.7213 - val_accuracy: 0.0917\n",
            "Epoch 48/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.0921 - accuracy: 0.3425 - val_loss: 1.7176 - val_accuracy: 0.0914\n",
            "Epoch 49/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.0932 - accuracy: 0.3410 - val_loss: 1.7209 - val_accuracy: 0.0931\n",
            "Epoch 50/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.0939 - accuracy: 0.3409 - val_loss: 1.7514 - val_accuracy: 0.0883\n",
            "Epoch 51/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.0959 - accuracy: 0.3420 - val_loss: 1.7379 - val_accuracy: 0.0896\n",
            "Epoch 52/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.0961 - accuracy: 0.3410 - val_loss: 1.7235 - val_accuracy: 0.0884\n",
            "Epoch 53/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.0965 - accuracy: 0.3404 - val_loss: 1.7099 - val_accuracy: 0.0907\n",
            "Epoch 54/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.0968 - accuracy: 0.3404 - val_loss: 1.7209 - val_accuracy: 0.0891\n",
            "Epoch 55/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.0983 - accuracy: 0.3399 - val_loss: 1.7171 - val_accuracy: 0.0892\n",
            "Epoch 56/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.0995 - accuracy: 0.3400 - val_loss: 1.7637 - val_accuracy: 0.0859\n",
            "Epoch 57/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.1003 - accuracy: 0.3394 - val_loss: 1.7168 - val_accuracy: 0.0888\n",
            "Epoch 58/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.1013 - accuracy: 0.3395 - val_loss: 1.7121 - val_accuracy: 0.0878\n",
            "Epoch 59/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.1025 - accuracy: 0.3394 - val_loss: 1.7013 - val_accuracy: 0.0899\n",
            "Epoch 60/60\n",
            "1382/1382 [==============================] - 12s 9ms/step - loss: 0.1019 - accuracy: 0.3391 - val_loss: 1.7237 - val_accuracy: 0.0873\n",
            "lol\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 1698<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "08ee7c96b7c64f3c9798670c1a953287",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 5.05MB of 5.05MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210430_175948-h4d1mleg/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210430_175948-h4d1mleg/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>epoch</td><td>59</td></tr><tr><td>loss</td><td>0.1043</td></tr><tr><td>accuracy</td><td>0.33862</td></tr><tr><td>val_loss</td><td>1.72374</td></tr><tr><td>val_accuracy</td><td>0.08725</td></tr><tr><td>_runtime</td><td>737</td></tr><tr><td>_timestamp</td><td>1619806325</td></tr><tr><td>_step</td><td>59</td></tr><tr><td>best_val_loss</td><td>1.11063</td></tr><tr><td>best_epoch</td><td>0</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>accuracy</td><td>▁▄▆▇▇▇██████████████████████████████████</td></tr><tr><td>val_loss</td><td>▁▄▆▆▆▇▆▇▇▇▇█▇██▇██▇███████████▇▇▇█▇▇▇█▇▇</td></tr><tr><td>val_accuracy</td><td>█▁▃▄▄▄▅▅▅▅▄▄▅▅▅▅▅▅▅▅▄▄▅▄▄▄▄▄▄▄▄▄▄▃▃▄▃▃▃▃</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">stoic-sweep-1</strong>: <a href=\"https://wandb.ai/narendv/CS6910-assg3/runs/h4d1mleg\" target=\"_blank\">https://wandb.ai/narendv/CS6910-assg3/runs/h4d1mleg</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Exiting.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElpQiw-l7KUg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}