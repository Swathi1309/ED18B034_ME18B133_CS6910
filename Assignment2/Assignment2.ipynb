{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Swathi1309/ED18B034_ME18B133_Assignment1/blob/main/Assignment2/Assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwpC4SmUV2Am"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv1D,Conv2D, BatchNormalization, Dropout, Activation, Softmax, MaxPooling2D\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import random\n",
        "import pprint\n",
        "\n",
        "from  matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qDInjFlMBk3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a60c3f51-a5ce-42ee-80ac-2964eabe422e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "classes = ['Amphibia', 'Animalia', 'Arachnida', 'Aves', 'Fungi', 'Insecta', 'Mammalia', 'Mollusca', 'Plantae', 'Reptilia']"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gXqxZPXD-ZK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5aa86f7-12fc-4223-f094-52d0e5d808f3"
      },
      "source": [
        "!pip install wandb\n",
        "!wandb login\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "wandb.init(project=\"CS6910-assg2\", entity=\"swathi\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wandb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/47/af/4cfe48fe55046181b992251933cff4ceb3bfd71a42838f5fe683683cd925/wandb-0.10.25-py2.py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 6.0MB/s \n",
            "\u001b[?25hCollecting GitPython>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/99/98019716955ba243657daedd1de8f3a88ca1f5b75057c38e959db22fb87b/GitPython-3.1.14-py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 22.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n",
            "Collecting subprocess32>=3.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 8.2MB/s \n",
            "\u001b[?25hCollecting shortuuid>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.12.4)\n",
            "Collecting pathtools\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Collecting sentry-sdk>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/92/5a33be64990ba815364a8f2dd9e6f51de60d23dfddafb4f1fc5577d4dc64/sentry_sdk-1.0.0-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 19.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/fd/01/ff260a18caaf4457eb028c96eeb405c4a230ca06c8ec9c1379f813caa52e/configparser-5.0.2-py3-none-any.whl\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.0->wandb) (54.2.0)\n",
            "Collecting smmap<5,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: subprocess32, pathtools\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp37-none-any.whl size=6489 sha256=138179ffe39b080b98f3f41b9fe8e4d32de9220b614b210045ef4f6813ec466d\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp37-none-any.whl size=8786 sha256=01d09b2ea624b221f5a35166b6cf76e5b0563b74ff758871d6e943eb2a17e115\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "Successfully built subprocess32 pathtools\n",
            "Installing collected packages: smmap, gitdb, GitPython, docker-pycreds, subprocess32, shortuuid, pathtools, sentry-sdk, configparser, wandb\n",
            "Successfully installed GitPython-3.1.14 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.7 pathtools-0.1.2 sentry-sdk-1.0.0 shortuuid-1.0.1 smmap-4.0.0 subprocess32-3.5.4 wandb-0.10.25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OM-zwdYSo1ap"
      },
      "source": [
        "def load_data(dir_train, dir_test, batch):\n",
        "  \n",
        "  seed = 42\n",
        "  \n",
        "  train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    samplewise_center = 0,\n",
        "    horizontal_flip = True,\n",
        "    rotation_range = 30,\n",
        "    validation_split = 0.1)\n",
        "  \n",
        "  val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    samplewise_center = 0,\n",
        "    validation_split = 0.1)\n",
        "  \n",
        "  test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    samplewise_center = 0)\n",
        "  \n",
        "  train_aug_dataset = train_datagen.flow_from_directory(\n",
        "    dir_train,\n",
        "    target_size = (img_dim,img_dim),\n",
        "    batch_size = batch,\n",
        "    classes = ['Amphibia', 'Animalia', 'Arachnida', 'Aves', 'Fungi', 'Insecta', 'Mammalia', 'Mollusca', 'Plantae', 'Reptilia'],\n",
        "    class_mode='categorical',\n",
        "    subset = 'training',\n",
        "    seed = seed)\n",
        "\n",
        "  train_dataset = val_datagen.flow_from_directory(\n",
        "    dir_train,\n",
        "    target_size = (img_dim,img_dim),\n",
        "    batch_size = batch,\n",
        "    classes = ['Amphibia', 'Animalia', 'Arachnida', 'Aves', 'Fungi', 'Insecta', 'Mammalia', 'Mollusca', 'Plantae', 'Reptilia'],\n",
        "    class_mode='categorical',\n",
        "    subset = 'training',\n",
        "    seed = seed)\n",
        "  \n",
        "  val_dataset = val_datagen.flow_from_directory(\n",
        "    dir_train,\n",
        "    target_size = (img_dim,img_dim),\n",
        "    batch_size = batch,\n",
        "    classes = ['Amphibia', 'Animalia', 'Arachnida', 'Aves', 'Fungi', 'Insecta', 'Mammalia', 'Mollusca', 'Plantae', 'Reptilia'],\n",
        "    class_mode='categorical',\n",
        "    subset = 'validation',\n",
        "    seed = seed)\n",
        "  \n",
        "  test_dataset = test_datagen.flow_from_directory(\n",
        "    dir_test,\n",
        "    target_size = (img_dim,img_dim),\n",
        "    batch_size = batch,\n",
        "    classes = ['Amphibia', 'Animalia', 'Arachnida', 'Aves', 'Fungi', 'Insecta', 'Mammalia', 'Mollusca', 'Plantae', 'Reptilia'],\n",
        "    class_mode='categorical',\n",
        "    subset = None,\n",
        "    seed = seed\n",
        "  )\n",
        "  \n",
        "  return train_aug_dataset, train_dataset, val_dataset, test_dataset"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzIoeqngVtLq"
      },
      "source": [
        "def CNN_wo_BN(filter_matrix, kernel_matrix, activation_matrix, fdropout, dense_no, learning_rate):\n",
        "\n",
        "  # Input layer\n",
        "  X_input = keras.Input(shape=(img_dim,img_dim,channel_no))\n",
        "\n",
        "  # Layer 1\n",
        "  X = Conv2D(filter_matrix[0], kernel_matrix[0])(X_input)\n",
        "  X = Activation(activation_matrix[0])(X)\n",
        "  X = MaxPooling2D(pool_size=(2, 2))(X)\n",
        "\n",
        "  # Layer 2\n",
        "  X = Conv2D(filter_matrix[1], kernel_matrix[1])(X)\n",
        "  X = Activation(activation_matrix[1])(X)\n",
        "  X = MaxPooling2D(pool_size=(2, 2))(X)\n",
        "\n",
        "  # Layer 3\n",
        "  X = Conv2D(filter_matrix[2], kernel_matrix[2])(X)\n",
        "  X = Activation(activation_matrix[2])(X)\n",
        "  X = MaxPooling2D(pool_size=(2, 2))(X)\n",
        "\n",
        "  # Layer 4\n",
        "  X = Conv2D(filter_matrix[3], kernel_matrix[3])(X)\n",
        "  X = Activation(activation_matrix[3])(X)\n",
        "  X = MaxPooling2D(pool_size=(2, 2))(X)\n",
        "\n",
        "  # Layer 5\n",
        "  X = Conv2D(filter_matrix[4], kernel_matrix[4])(X)\n",
        "  X = Activation(activation_matrix[4])(X)\n",
        "  X = MaxPooling2D(pool_size=(2, 2))(X)\n",
        "\n",
        "  X = Flatten()(X)\n",
        "  X = Dense(dense_no,activation=activation_matrix[5])(X)\n",
        "  X = Dropout(fdropout)(X)\n",
        "  X = Dense(10,activation='softmax')(X)\n",
        "  \n",
        "  model=Model(inputs=X_input,outputs=X)\n",
        "  model.compile(optimizer=Adam(learning_rate), loss='categorical_crossentropy',  metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvurXgaSfK8U"
      },
      "source": [
        "def CNN_w_BN(filter_matrix, kernel_matrix, activation_matrix, fdropout, dense_no, learning_rate):\n",
        "\n",
        "  # Input layer\n",
        "  X_input = keras.Input(shape=(img_dim,img_dim,channel_no))\n",
        "\n",
        "  # Layer 1\n",
        "  X = Conv2D(filter_matrix[0], kernel_matrix[0])(X_input)\n",
        "  X = BatchNormalization()(X)\n",
        "  X = Activation(activation_matrix[0])(X)\n",
        "  X = MaxPooling2D(pool_size=(2, 2))(X)\n",
        "\n",
        "  # Layer 2\n",
        "  X = Conv2D(filter_matrix[1], kernel_matrix[1])(X)\n",
        "  X = BatchNormalization()(X)\n",
        "  X = Activation(activation_matrix[1])(X)\n",
        "  X = MaxPooling2D(pool_size=(2, 2))(X)\n",
        "\n",
        "  # Layer 3\n",
        "  X = Conv2D(filter_matrix[2], kernel_matrix[2])(X)\n",
        "  X = BatchNormalization()(X)\n",
        "  X = Activation(activation_matrix[2])(X)\n",
        "  X = MaxPooling2D(pool_size=(2, 2))(X)\n",
        "\n",
        "  # Layer 4\n",
        "  X = Conv2D(filter_matrix[3], kernel_matrix[3])(X)\n",
        "  X = BatchNormalization()(X)\n",
        "  X = Activation(activation_matrix[3])(X)\n",
        "  X = MaxPooling2D(pool_size=(2, 2))(X)\n",
        "\n",
        "  # Layer 5\n",
        "  X = Conv2D(filter_matrix[4], kernel_matrix[4])(X)\n",
        "  X = BatchNormalization()(X)\n",
        "  X = Activation(activation_matrix[4])(X)\n",
        "  X = MaxPooling2D(pool_size=(2, 2))(X)\n",
        "\n",
        "  X = Flatten()(X)\n",
        "  X = Dense(dense_no,activation=activation_matrix[5])(X)\n",
        "  X = Dropout(fdropout)(X)\n",
        "  X = Dense(10,activation='softmax')(X)\n",
        "  \n",
        "  model=Model(inputs=X_input,outputs=X)\n",
        "  model.compile(optimizer=Adam(learning_rate), loss='categorical_crossentropy',  metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKPL9RF3Xrs9"
      },
      "source": [
        "def model_choose(filter_matrix, kernel_matrix, activation_matrix, dropout, dense_no, batch_norm, learning_rate):\n",
        "  wandb.log({\"Filters\": filter_matrix})\n",
        "  if batch_norm == True:\n",
        "    model = CNN_w_BN(filter_matrix, kernel_matrix, activation_matrix, dropout, dense_no, learning_rate)\n",
        "  else:\n",
        "    model = CNN_wo_BN(filter_matrix, kernel_matrix, activation_matrix, dropout, dense_no, learning_rate)\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0fTjJp1c2SF"
      },
      "source": [
        "@tf.custom_gradient\n",
        "def GBRelu(x):\n",
        "  def gradient(dy):\n",
        "    grad = tf.cast(dy>0,\"float32\")*tf.cast(x>0, \"float32\")*dy\n",
        "    return  grad\n",
        "  return tf.nn.relu(x), gradient\n",
        "# Here model is the best model\n",
        "GBModel = Model(inputs = [model.inputs],outputs = [model.get_layer(index=8).output]) # Here the index is to be checked\n",
        "layer_dict = [layer for layer in gb_model.layers[1:] if hasattr(layer,'activation')]\n",
        "for layer in layer_dict:\n",
        "  if layer.activation == tf.keras.activations.relu:\n",
        "    layer.activation = GBRelu\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "  inputs = tf.cast(X_input, tf.float32)\n",
        "  tape.watch(inputs)\n",
        "  outputs = GBModel(inputs)\n",
        "\n",
        "grads = tape.gradient(outputs,inputs)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6V3TPqY4Bj_4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1b8020f-f548-4f46-de6e-c3cda86c7bd3"
      },
      "source": [
        "sweep_config = {\n",
        "    'method': 'grid'\n",
        "    }\n",
        "\n",
        "parameters_dict = {\n",
        "    'filter_matrix':{\n",
        "        'values': [2]\n",
        "      },\n",
        "    'kernel_matrix': {\n",
        "        'values': [0]\n",
        "      },\n",
        "    'activation_matrix': {\n",
        "        'values': [0]\n",
        "      },\n",
        "    'learn_rate': {\n",
        "        'values': [1e-3]\n",
        "      },\n",
        "    'epochs': {\n",
        "        'values': [80]\n",
        "      },\n",
        "    'dropout': {\n",
        "        'values': [0.2]\n",
        "      },\n",
        "    'batch_normalization': {\n",
        "        'values': [True]\n",
        "      },\n",
        "    'dense_number': {\n",
        "          'values': [512]\n",
        "      },\n",
        "    'augmentation':{\n",
        "        'values' : [True]\n",
        "      }\n",
        "}\n",
        "sweep_config['parameters'] = parameters_dict\n",
        "pprint.pprint(sweep_config)\n",
        "\n",
        "def training_sweep(config=None):\n",
        "    with wandb.init(config=config):\n",
        "        config = wandb.config\n",
        "\n",
        "        F = filters[config.filter_matrix]\n",
        "        K = kernels[config.kernel_matrix]\n",
        "        A = activations[config.activation_matrix]\n",
        "\n",
        "        model = model_choose(F, K, A, config.dropout, config.dense_number, config.batch_normalization, config.learn_rate)\n",
        "        if config.augmentation == True:\n",
        "          train = train_aug_dataset\n",
        "        else:\n",
        "          train = train_dataset\n",
        "\n",
        "        history = model.fit(train, \n",
        "                            epochs=config.epochs,\n",
        "                            validation_data = val_dataset,\n",
        "                            callbacks = [WandbCallback(data_type='image', labels = classes)]\n",
        "                            )\n",
        "        wandb.log(history.history)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'method': 'grid',\n",
            " 'parameters': {'activation_matrix': {'values': [0]},\n",
            "                'augmentation': {'values': [True]},\n",
            "                'batch_normalization': {'values': [True]},\n",
            "                'dense_number': {'values': [512]},\n",
            "                'dropout': {'values': [0.2]},\n",
            "                'epochs': {'values': [80]},\n",
            "                'filter_matrix': {'values': [2]},\n",
            "                'kernel_matrix': {'values': [0]},\n",
            "                'learn_rate': {'values': [0.001]}}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-wIWL35EhgC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66c411da-aa74-4f9b-e0da-6f69d6ad79e8"
      },
      "source": [
        "global img_dim\n",
        "img_dim = 200\n",
        "\n",
        "global channel_no\n",
        "channel_no = 3 #3 for RGB images, 1 for greyscale\n",
        "\n",
        "global batch\n",
        "batch = 128\n",
        "\n",
        "global filters\n",
        "filters = [[64,128,256,512,512],[64,128,256,256,512],[128,256,256,512,512],[96,128,256,512,512]]\n",
        "\n",
        "global kernels\n",
        "kernels = [[(3,3)]*5]\n",
        "\n",
        "global activations\n",
        "activations = [['relu']*6]\n",
        "\n",
        "global F, K, A\n",
        "\n",
        "global train_aug_dataset, train_dataset, val_dataset, test_datagen\n",
        "train_aug_dataset, train_dataset, val_dataset, test_dataset = load_data('/content/drive/MyDrive/inaturalist_12K/train', '/content/drive/MyDrive/inaturalist_12K/val', batch)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 9018 images belonging to 10 classes.\n",
            "Found 9018 images belonging to 10 classes.\n",
            "Found 1001 images belonging to 10 classes.\n",
            "Found 2000 images belonging to 10 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Agmt-aMLNOFu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f74903ce-dcbf-446f-ca63-8d33e295a540"
      },
      "source": [
        "sweep_id = wandb.sweep(sweep_config, project=\"CS6910-assg2\")\n",
        "wandb.agent(sweep_id, training_sweep)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Create sweep with ID: ci6pf4cp\n",
            "Sweep URL: https://wandb.ai/swathi/CS6910-assg2/sweeps/ci6pf4cp\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zbc1khhk with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_matrix: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \taugmentation: True\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_normalization: True\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_number: 512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 80\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_matrix: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_matrix: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearn_rate: 0.001\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.25<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">clean-sweep-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/swathi/CS6910-assg2\" target=\"_blank\">https://wandb.ai/swathi/CS6910-assg2</a><br/>\n",
              "                Sweep page: <a href=\"https://wandb.ai/swathi/CS6910-assg2/sweeps/ci6pf4cp\" target=\"_blank\">https://wandb.ai/swathi/CS6910-assg2/sweeps/ci6pf4cp</a><br/>\n",
              "Run page: <a href=\"https://wandb.ai/swathi/CS6910-assg2/runs/zbc1khhk\" target=\"_blank\">https://wandb.ai/swathi/CS6910-assg2/runs/zbc1khhk</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210406_115915-zbc1khhk</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n",
            "71/71 [==============================] - 3651s 51s/step - loss: 5.9686 - accuracy: 0.1287 - val_loss: 2.2951 - val_accuracy: 0.1209\n",
            "Epoch 2/80\n",
            "71/71 [==============================] - 239s 3s/step - loss: 2.2129 - accuracy: 0.1777 - val_loss: 2.3100 - val_accuracy: 0.1109\n",
            "Epoch 3/80\n",
            "71/71 [==============================] - 222s 3s/step - loss: 2.1515 - accuracy: 0.2180 - val_loss: 2.3578 - val_accuracy: 0.1099\n",
            "Epoch 4/80\n",
            "71/71 [==============================] - 216s 3s/step - loss: 2.0885 - accuracy: 0.2554 - val_loss: 2.3771 - val_accuracy: 0.1489\n",
            "Epoch 5/80\n",
            "71/71 [==============================] - 217s 3s/step - loss: 2.0522 - accuracy: 0.2495 - val_loss: 2.3987 - val_accuracy: 0.1369\n",
            "Epoch 6/80\n",
            "71/71 [==============================] - 221s 3s/step - loss: 2.0175 - accuracy: 0.2737 - val_loss: 2.3232 - val_accuracy: 0.1558\n",
            "Epoch 7/80\n",
            "71/71 [==============================] - 219s 3s/step - loss: 1.9970 - accuracy: 0.2866 - val_loss: 2.1310 - val_accuracy: 0.2058\n",
            "Epoch 8/80\n",
            "71/71 [==============================] - 217s 3s/step - loss: 1.9307 - accuracy: 0.3067 - val_loss: 2.1094 - val_accuracy: 0.2757\n",
            "Epoch 9/80\n",
            "71/71 [==============================] - 223s 3s/step - loss: 1.9187 - accuracy: 0.3070 - val_loss: 2.1868 - val_accuracy: 0.2398\n",
            "Epoch 10/80\n",
            "71/71 [==============================] - 214s 3s/step - loss: 1.9121 - accuracy: 0.3166 - val_loss: 2.0567 - val_accuracy: 0.2797\n",
            "Epoch 11/80\n",
            "71/71 [==============================] - 222s 3s/step - loss: 1.8906 - accuracy: 0.3330 - val_loss: 2.0626 - val_accuracy: 0.3117\n",
            "Epoch 12/80\n",
            "71/71 [==============================] - 219s 3s/step - loss: 1.8537 - accuracy: 0.3396 - val_loss: 2.1282 - val_accuracy: 0.2777\n",
            "Epoch 13/80\n",
            "71/71 [==============================] - 212s 3s/step - loss: 1.8378 - accuracy: 0.3423 - val_loss: 2.1322 - val_accuracy: 0.2837\n",
            "Epoch 14/80\n",
            "71/71 [==============================] - 215s 3s/step - loss: 1.8172 - accuracy: 0.3490 - val_loss: 2.2473 - val_accuracy: 0.3057\n",
            "Epoch 15/80\n",
            "71/71 [==============================] - 218s 3s/step - loss: 1.8161 - accuracy: 0.3456 - val_loss: 1.9705 - val_accuracy: 0.3067\n",
            "Epoch 16/80\n",
            "71/71 [==============================] - 218s 3s/step - loss: 1.7863 - accuracy: 0.3701 - val_loss: 2.2408 - val_accuracy: 0.2717\n",
            "Epoch 17/80\n",
            "71/71 [==============================] - 217s 3s/step - loss: 1.7735 - accuracy: 0.3642 - val_loss: 2.0376 - val_accuracy: 0.3067\n",
            "Epoch 18/80\n",
            "71/71 [==============================] - 218s 3s/step - loss: 1.7455 - accuracy: 0.3777 - val_loss: 2.1068 - val_accuracy: 0.2987\n",
            "Epoch 19/80\n",
            "71/71 [==============================] - 219s 3s/step - loss: 1.7184 - accuracy: 0.3853 - val_loss: 2.1449 - val_accuracy: 0.2507\n",
            "Epoch 20/80\n",
            "71/71 [==============================] - 217s 3s/step - loss: 1.7083 - accuracy: 0.3897 - val_loss: 3.4404 - val_accuracy: 0.2008\n",
            "Epoch 21/80\n",
            "71/71 [==============================] - 218s 3s/step - loss: 1.6933 - accuracy: 0.4023 - val_loss: 1.8656 - val_accuracy: 0.3786\n",
            "Epoch 22/80\n",
            "71/71 [==============================] - 217s 3s/step - loss: 1.6770 - accuracy: 0.4055 - val_loss: 1.8869 - val_accuracy: 0.3666\n",
            "Epoch 23/80\n",
            "71/71 [==============================] - 219s 3s/step - loss: 1.6787 - accuracy: 0.4045 - val_loss: 1.8977 - val_accuracy: 0.3826\n",
            "Epoch 24/80\n",
            "71/71 [==============================] - 219s 3s/step - loss: 1.6412 - accuracy: 0.4087 - val_loss: 1.9673 - val_accuracy: 0.3636\n",
            "Epoch 25/80\n",
            "71/71 [==============================] - 215s 3s/step - loss: 1.5948 - accuracy: 0.4363 - val_loss: 2.2003 - val_accuracy: 0.3017\n",
            "Epoch 26/80\n",
            "71/71 [==============================] - 218s 3s/step - loss: 1.6197 - accuracy: 0.4269 - val_loss: 1.8130 - val_accuracy: 0.3836\n",
            "Epoch 27/80\n",
            "71/71 [==============================] - 220s 3s/step - loss: 1.5930 - accuracy: 0.4371 - val_loss: 1.7904 - val_accuracy: 0.4056\n",
            "Epoch 28/80\n",
            "71/71 [==============================] - 221s 3s/step - loss: 1.5911 - accuracy: 0.4286 - val_loss: 1.9181 - val_accuracy: 0.3726\n",
            "Epoch 29/80\n",
            "71/71 [==============================] - 217s 3s/step - loss: 1.5782 - accuracy: 0.4314 - val_loss: 1.9571 - val_accuracy: 0.3946\n",
            "Epoch 30/80\n",
            "71/71 [==============================] - 219s 3s/step - loss: 1.5479 - accuracy: 0.4488 - val_loss: 1.9096 - val_accuracy: 0.3656\n",
            "Epoch 31/80\n",
            "71/71 [==============================] - 219s 3s/step - loss: 1.5114 - accuracy: 0.4653 - val_loss: 1.8309 - val_accuracy: 0.3886\n",
            "Epoch 32/80\n",
            "71/71 [==============================] - 217s 3s/step - loss: 1.5069 - accuracy: 0.4610 - val_loss: 1.9968 - val_accuracy: 0.3586\n",
            "Epoch 33/80\n",
            "71/71 [==============================] - 219s 3s/step - loss: 1.4913 - accuracy: 0.4648 - val_loss: 1.7909 - val_accuracy: 0.3896\n",
            "Epoch 34/80\n",
            "71/71 [==============================] - 218s 3s/step - loss: 1.4833 - accuracy: 0.4653 - val_loss: 1.8417 - val_accuracy: 0.3926\n",
            "Epoch 35/80\n",
            "71/71 [==============================] - 219s 3s/step - loss: 1.4309 - accuracy: 0.4848 - val_loss: 2.1565 - val_accuracy: 0.3307\n",
            "Epoch 36/80\n",
            "71/71 [==============================] - 218s 3s/step - loss: 1.4283 - accuracy: 0.4798 - val_loss: 1.7743 - val_accuracy: 0.4086\n",
            "Epoch 37/80\n",
            "71/71 [==============================] - 219s 3s/step - loss: 1.4149 - accuracy: 0.4943 - val_loss: 1.7991 - val_accuracy: 0.3946\n",
            "Epoch 38/80\n",
            "71/71 [==============================] - 219s 3s/step - loss: 1.3755 - accuracy: 0.5140 - val_loss: 2.6780 - val_accuracy: 0.2747\n",
            "Epoch 39/80\n",
            "71/71 [==============================] - 223s 3s/step - loss: 1.3520 - accuracy: 0.5081 - val_loss: 1.8210 - val_accuracy: 0.3996\n",
            "Epoch 40/80\n",
            "71/71 [==============================] - 221s 3s/step - loss: 1.3400 - accuracy: 0.5287 - val_loss: 1.9502 - val_accuracy: 0.3736\n",
            "Epoch 41/80\n",
            "71/71 [==============================] - 219s 3s/step - loss: 1.2957 - accuracy: 0.5385 - val_loss: 1.7748 - val_accuracy: 0.4266\n",
            "Epoch 42/80\n",
            "71/71 [==============================] - 219s 3s/step - loss: 1.2980 - accuracy: 0.5347 - val_loss: 1.9179 - val_accuracy: 0.3826\n",
            "Epoch 43/80\n",
            "71/71 [==============================] - 219s 3s/step - loss: 1.3165 - accuracy: 0.5276 - val_loss: 1.8711 - val_accuracy: 0.3876\n",
            "Epoch 44/80\n",
            "71/71 [==============================] - 216s 3s/step - loss: 1.2779 - accuracy: 0.5476 - val_loss: 2.0428 - val_accuracy: 0.3676\n",
            "Epoch 45/80\n",
            "71/71 [==============================] - 218s 3s/step - loss: 1.2426 - accuracy: 0.5528 - val_loss: 1.9810 - val_accuracy: 0.3926\n",
            "Epoch 46/80\n",
            "43/71 [=================>............] - ETA: 1:20 - loss: 1.2348 - accuracy: 0.5451"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aX9VMMRf6Im",
        "outputId": "26ff9b1b-c1d1-4c18-91e7-25e4cd928e08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "wandb.agent(sweep_id, training_sweep)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-5fde527b735f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msweep_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_sweep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'wandb' is not defined"
          ]
        }
      ]
    }
  ]
}