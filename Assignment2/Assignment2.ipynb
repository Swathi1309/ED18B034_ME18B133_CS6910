{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Swathi1309/ED18B034_ME18B133_Assignment1/blob/main/Assignment2/Assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwpC4SmUV2Am"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv1D,Conv2D, BatchNormalization, Dropout, Activation, Softmax, MaxPooling2D\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.optimizers import Adam,RMSprop\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "from  matplotlib import pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import random\n",
        "%matplotlib inline\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "classes = ['Amphibia', 'Animalia', 'Arachnida', 'Aves', 'Fungi', 'Insecta', 'Mammalia', 'Mollusca', 'Plantae', 'Reptilia']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Wlkd47bFHtp"
      },
      "source": [
        "def load_dataset(img_folder):\n",
        "  IMG_WIDTH=200\n",
        "  IMG_HEIGHT=200\n",
        "  x=[]\n",
        "  y=[]\n",
        "  for dir_name in os.listdir(img_folder):\n",
        "    for file in os.listdir(os.path.join(img_folder, dir_name)):\n",
        "      img_path = os.path.join(img_folder, dir_name, file)\n",
        "      img = cv2.imread(img_path, cv2.COLOR_BGR2RGB)\n",
        "      #image = cv2.resize(img, (IMG_HEIGHT, IMG_WIDTH),interpolation = cv2.INTER_AREA)\n",
        "      image = (np.array(img)).astype('float32')\n",
        "      image /= 255\n",
        "      x.append(image)\n",
        "      y.append(classes.index(dir_name))\n",
        "  return x, y"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6Nw1GdxLILB"
      },
      "source": [
        "def load_data():\n",
        "  X, Y = load_dataset('/content/drive/MyDrive/inaturalist_12K/train')\n",
        "  x_test, y_test = load_dataset('/content/drive/MyDrive/inaturalist_12K/val')\n",
        "  x_train, x_val, y_train, y_val = train_test_split(X, Y, test_size = 0.1, stratify = Y)\n",
        "\n",
        "  return x_train, y_train, x_val, y_val, x_test, y_test"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49recRaTLhPK"
      },
      "source": [
        "x_train, y_train, x_val, y_val, x_test, y_test = load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMRPMBILWN43"
      },
      "source": [
        "x_test, y_test = load_dataset('/content/drive/MyDrive/inaturalist_12K/val')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Yh5ZT9IQFba"
      },
      "source": [
        "def augmentation(x, y, frac_hor, frac_vert, frac_flip):\n",
        "  num = int(frac_hor*x.shape[0])\n",
        "  rand_num_arr_hor = np.random.randint(x.shape[0]-1,size =(num))\n",
        "  image = x[rand_num_arr_hor]\n",
        "  for img in image:\n",
        "    flipped = tf.image.flip_left_right(img)\n",
        "    x_new = x.append(flipped)\n",
        "  y_new = y.append(y[rand_num_arr_hor])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzIoeqngVtLq"
      },
      "source": [
        "def CNN_wo_BN(X_train, filter_matrix, kernel_matrix, activation_matrix, fdropout=0, dense_no=512, learning_rate=0.001):\n",
        "\n",
        "  # Input layer\n",
        "  X_input = keras.Input(shape=X_train.shape)\n",
        "\n",
        "  # Layer 1\n",
        "  X = Conv2D(filter_matrix[0], kernel_matrix[0])(X_input)\n",
        "  X = Activation(activation_matrix[0])(X)\n",
        "  X = MaxPooling2D(pool_size=(2, 2))(X)\n",
        "\n",
        "  # Layer 2\n",
        "  X = Conv2D(filter_matrix[1], kernel_matrix[1])(X)\n",
        "  X = Activation(activation_matrix[1])(X)\n",
        "  X = MaxPooling2D(pool_size=(2, 2))(X)\n",
        "\n",
        "  # Layer 3\n",
        "  X = Conv2D(filter_matrix[2], kernel_matrix[2])(X)\n",
        "  X = Activation(activation_matrix[2])(X)\n",
        "  X = MaxPooling2D(pool_size=(2, 2))(X)\n",
        "\n",
        "  # Layer 4\n",
        "  X = Conv2D(filter_matrix[3], kernel_matrix[3])(X)\n",
        "  X = Activation(activation_matrix[3])(X)\n",
        "  X = MaxPooling2D(pool_size=(2, 2))(X)\n",
        "\n",
        "  # Layer 5\n",
        "  X = Conv2D(filter_matrix[4], kernel_matrix[4])(X)\n",
        "  X = Activation(activation_matrix[4])(X)\n",
        "  X = MaxPooling2D(pool_size=(2, 2))(X)\n",
        "\n",
        "  X = Flatten()(X)\n",
        "  X = Dense(dense_no,activation=activation_matrix[5])(X)\n",
        "  X = Dropout(fdropout)(X)\n",
        "  X = Dense(10,activation='softmax')(X)\n",
        "  \n",
        "  model=Model(inputs=X_input,outputs=X)\n",
        "  model.compile(optimizer=Adam(learning_rate), loss='categorical_crossentropy',  metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvurXgaSfK8U"
      },
      "source": [
        "def CNN_w_BN(X_train, filter_matrix, kernel_matrix, activation_matrix, fdropout=0, dense_no=512, learning_rate=0.001):\n",
        "\n",
        "  # Input layer\n",
        "  X_input = keras.Input(shape=X_train.shape)\n",
        "\n",
        "  # Layer 1\n",
        "  X = Conv2D(filter_matrix[0], kernel_matrix[0])(X_input)\n",
        "  X = BatchNormalization()(X)\n",
        "  X = Activation(activation_matrix[0])(X)\n",
        "  X = MaxPooling2D(pool_size=(2, 2))(X)\n",
        "\n",
        "  # Layer 2\n",
        "  X = Conv2D(filter_matrix[1], kernel_matrix[1])(X)\n",
        "  X = BatchNormalization()(X)\n",
        "  X = Activation(activation_matrix[1])(X)\n",
        "  X = MaxPooling2D(pool_size=(2, 2))(X)\n",
        "\n",
        "  # Layer 3\n",
        "  X = Conv2D(filter_matrix[2], kernel_matrix[2])(X)\n",
        "  X = BatchNormalization()(X)\n",
        "  X = Activation(activation_matrix[2])(X)\n",
        "  X = MaxPooling2D(pool_size=(2, 2))(X)\n",
        "\n",
        "  # Layer 4\n",
        "  X = Conv2D(filter_matrix[3], kernel_matrix[3])(X)\n",
        "  X = BatchNormalization()(X)\n",
        "  X = Activation(activation_matrix[3])(X)\n",
        "  X = MaxPooling2D(pool_size=(2, 2))(X)\n",
        "\n",
        "  # Layer 5\n",
        "  X = Conv2D(filter_matrix[4], kernel_matrix[4])(X)\n",
        "  X = BatchNormalization()(X)\n",
        "  X = Activation(activation_matrix[4])(X)\n",
        "  X = MaxPooling2D(pool_size=(2, 2))(X)\n",
        "\n",
        "  X = Flatten()(X)\n",
        "  X = Dense(dense_no,activation=activation_matrix[5])(X)\n",
        "  X = Dropout(fdropout)(X)\n",
        "  X = Dense(10,activation='softmax')(X)\n",
        "  \n",
        "  model=Model(inputs=X_input,outputs=X)\n",
        "  model.compile(optimizer=Adam(learning_rate), loss='categorical_crossentropy',  metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKPL9RF3Xrs9"
      },
      "source": [
        "def model_choose(X_train, highest_filter, filter_type, kernel_matrix, activation_matrix, dropout=0, dense_no=512, batch_norm=True, learning_rate=0.001):\n",
        "  if filter_type == 'constant':\n",
        "    filter_matrix = [filter_start]*4\n",
        "  elif filter_type == 'doubling':\n",
        "    filter_matrix = [highest_filter/16, highest_filter/8, highest_filter/4, highest_filter/2, highest_filter]\n",
        "  elif filter_type == 'halving':\n",
        "    filter_matrix = [highest_filter, highest_filter/2, highest_filter/4, highest_filter/8, highest_filter/16]\n",
        "  # wandb.log({\"Filters\": filter_matrix})\n",
        "\n",
        "  if batch_norm == True:\n",
        "    model = CNN_w_BN(X_train, filter_matrix, kernel_matrix, activation_matrix, dropout, dense_no, learning_rate)\n",
        "  else:\n",
        "    model = CNN_wo_BN(X_train, filter_matrix, kernel_matrix, activation_matrix, dropout, dense_no, learning_rate)\n",
        "  \n",
        "  return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0Z8EWSzAYtv"
      },
      "source": [
        "# Checking all above functions\n",
        "X=tf.random.normal((227,227,3))\n",
        "filter_matrix = [32, 64, 256, 512, 1024]\n",
        "kernel_matrix = [(3,3)]*5\n",
        "activation_matrix = ['relu']*6;\n",
        "model = model_choose(X, 1024, 'doubling', kernel_matrix, activation_matrix)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0fTjJp1c2SF"
      },
      "source": [
        "@tf.custom_gradient\n",
        "def GBRelu(x):\n",
        "  def gradient(dy):\n",
        "    grad = tf.cast(dy>0,\"float32\")*tf.cast(x>0, \"float32\")*dy\n",
        "    return  grad\n",
        "  return tf.nn.relu(x), gradient\n",
        "# Here model is the best model\n",
        "GBModel = Model(inputs = [model.inputs],outputs = [model.get_layer(index=8).output]) # Here the index is to be checked\n",
        "layer_dict = [layer for layer in gb_model.layers[1:] if hasattr(layer,'activation')]\n",
        "for layer in layer_dict:\n",
        "  if layer.activation == tf.keras.activations.relu:\n",
        "    layer.activation = GBRelu\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "  inputs = tf.cast(X_input, tf.float32)\n",
        "  tape.watch(inputs)\n",
        "  outputs = GBModel(inputs)\n",
        "\n",
        "grads = tape.gradient(outputs,inputs)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6V3TPqY4Bj_4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}