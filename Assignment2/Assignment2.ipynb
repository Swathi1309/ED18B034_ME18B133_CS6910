{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyONxSH3Oz17EhO+9cad8hOM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Swathi1309/ED18B034_ME18B133_Assignment1/blob/main/Assignment2/Assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwpC4SmUV2Am"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv1D,Conv2D, BatchNormalization, Dropout, Activation, Softmax, MaxPooling2D\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.optimizers import Adam,RMSprop\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzIoeqngVtLq"
      },
      "source": [
        "def CNN_wo_BN(X_train, filter_matrix, kernel_matrix, activation_matrix, fdropout, dense_no, learning_rate):\n",
        "\n",
        "  # Input layer\n",
        "  X_input = keras.Input(shape=X_train.shape)\n",
        "\n",
        "  # Layer 1\n",
        "  X = Conv2D(filter_matrix[0], kernel_matrix[0])(X_input)\n",
        "  X = Activation(activation_matrix[0])(X)\n",
        "  X = MaxPooling2D(pool_size=(2, 2))(X)\n",
        "\n",
        "  # Layer 2\n",
        "  X = Conv2D(filter_matrix[1], kernel_matrix[1])(X)\n",
        "  X = Activation(activation_matrix[1])(X)\n",
        "  X = MaxPooling2D(pool_size=(2, 2))(X)\n",
        "\n",
        "  # Layer 3\n",
        "  X = Conv2D(filter_matrix[2], kernel_matrix[2])(X)\n",
        "  X = Activation(activation_matrix[2])(X)\n",
        "  X = MaxPooling2D(pool_size=(2, 2))(X)\n",
        "\n",
        "  # Layer 4\n",
        "  X = Conv2D(filter_matrix[3], kernel_matrix[3])(X)\n",
        "  X = Activation(activation_matrix[3])(X)\n",
        "  X = MaxPooling2D(pool_size=(2, 2))(X)\n",
        "\n",
        "  # Layer 5\n",
        "  X = Conv2D(filter_matrix[4], kernel_matrix[4])(X)\n",
        "  X = Activation(activation_matrix[4])(X)\n",
        "  X = MaxPooling2D(pool_size=(2, 2))(X)\n",
        "\n",
        "  X = Flatten()(X)\n",
        "  X = Dense(dense_no,activation=activation_matrix[5])(X)\n",
        "  X = Dropout(fdropout)(X)\n",
        "  X = Dense(10,activation='softmax')(X)\n",
        "  \n",
        "  model=Model(inputs=X_input,outputs=X)\n",
        "  model.complile(optimizer=Adam(learning_rate), loss='categorical_crossentropy',  metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvurXgaSfK8U"
      },
      "source": [
        "def CNN_w_BN(X_train, filter_matrix, kernel_matrix, activation_matrix, fdropout, dense_no, learning_rate):\n",
        "\n",
        "  # Input layer\n",
        "  X_input = keras.Input(shape=X_train.shape)\n",
        "\n",
        "  # Layer 1\n",
        "  X = Conv2D(filter_matrix[0], kernel_matrix[0]))(X_input)\n",
        "  X = BatchNormalization()(X)\n",
        "  X = Activation(activation_matrix[0])(X)\n",
        "  X = MaxPooling2D(pool_size=(2, 2))(X)\n",
        "\n",
        "  # Layer 2\n",
        "  X = Conv2D(filter_matrix[1], kernel_matrix[1])(X)\n",
        "  X = BatchNormalization()(X)\n",
        "  X = Activation(activation_matrix[1])(X)\n",
        "  X = MaxPooling2D(pool_size=(2, 2))(X)\n",
        "\n",
        "  # Layer 3\n",
        "  X = Conv2D(filter_matrix[2], kernel_matrix[2])(X)\n",
        "  X = BatchNormalization()(X)\n",
        "  X = Activation(activation_matrix[2])(X)\n",
        "  X = MaxPooling2D(pool_size=(2, 2))(X)\n",
        "\n",
        "  # Layer 4\n",
        "  X = Conv2D(filter_matrix[3], kernel_matrix[3])(X)\n",
        "  X = BatchNormalization()(X)\n",
        "  X = Activation(activation_matrix[3])(X)\n",
        "  X = MaxPooling2D(pool_size=(2, 2))(X)\n",
        "\n",
        "  # Layer 5\n",
        "  X = Conv2D(filter_matrix[4], kernel_matrix[4])(X)\n",
        "  X = BatchNormalization()(X)\n",
        "  X = Activation(activation_matrix[4])(X)\n",
        "  X = MaxPooling2D(pool_size=(2, 2))(X)\n",
        "\n",
        "  X = Flatten()(X)\n",
        "  X = Dense(dense_no,activation=activation_matrix[5])(X)\n",
        "  X = Dropout(fdropout)(X)\n",
        "  X = Dense(10,activation='softmax')(X)\n",
        "  \n",
        "  model=Model(inputs=X_input,outputs=X)\n",
        "  model.complile(optimizer=Adam(learning_rate), loss='categorical_crossentropy',  metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKPL9RF3Xrs9"
      },
      "source": [
        "def model_choose(batch_norm, highest_filter, filters_type, dropout):\n",
        "  if filter_type == 'constant':\n",
        "    filter_matrix = [filter_start]*4\n",
        "  elif filter_type == 'doubling':\n",
        "    filter_matrix = [highest_filter/8, highest_filter/4, highest_filter/2, highest_filter]\n",
        "  else:\n",
        "    filter_matrix = [highest_filter, highest_filter/2, highest_filter/4, highest_filter/8]\n",
        "  wandb.log({\"Filters\": filter_matrix, \"Dropout\": dropout, \"Batch_norm\": batch_norm})\n",
        "\n",
        "  if batch_norm = True:\n",
        "    model = CNN_w_BN(X_train, filter_matrix, kernel_matrix, activation_matrix, dropout, dense_no)\n",
        "  else:\n",
        "    model = CNN_wo_BN(X_train, filter_matrix, kernel_matrix, activation_matrix, dropout, dense_no)\n",
        "  \n",
        "  return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0fTjJp1c2SF"
      },
      "source": [
        "@tf.custom_gradient\n",
        "def GBRelu(x):\n",
        "  def gradient(dy):\n",
        "    grad = tf.cast(dy>0,\"float32\")*tf.cast(x>0, \"float32\")*dy\n",
        "    return  grad\n",
        "  return tf.nn.relu(x), gradient\n",
        "# Here model is the best model\n",
        "GBModel = Model(inputs = [model.inputs],outputs = [model.get_layer(index=8).output]) # Here the index is to be checked\n",
        "layer_dict = [layer for layer in gb_model.layers[1:] if hasattr(layer,'activation')]\n",
        "for layer in layer_dict:\n",
        "  if layer.activation == tf.keras.activations.relu:\n",
        "    layer.activation = GBRelu\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "  inputs = tf.cast(X_input, tf.float32)\n",
        "  tape.watch(inputs)\n",
        "  outputs = GBModel(inputs)\n",
        "\n",
        "grads = tape.gradient(outputs,inputs)[0]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}