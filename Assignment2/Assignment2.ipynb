{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Swathi1309/ED18B034_ME18B133_Assignment1/blob/main/Assignment2/Assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwpC4SmUV2Am"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv1D,Conv2D, BatchNormalization, Dropout, Activation, Softmax, MaxPooling2D\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import random\n",
        "import pprint\n",
        "\n",
        "from  matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qDInjFlMBk3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "classes = ['Amphibia', 'Animalia', 'Arachnida', 'Aves', 'Fungi', 'Insecta', 'Mammalia', 'Mollusca', 'Plantae', 'Reptilia']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gXqxZPXD-ZK"
      },
      "source": [
        "!pip install wandb\n",
        "!wandb login\n",
        "import wandb\n",
        "wandb.init(project=\"CS6910-assg2\", entity=\"narendv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OM-zwdYSo1ap"
      },
      "source": [
        "def load_data(dir_train, dir_test, batch):\n",
        "  \n",
        "  seed = 42\n",
        "  \n",
        "  train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    samplewise_center = 0,\n",
        "    horizontal_flip = True,\n",
        "    rotation_range = 30,\n",
        "    validation_split = 0.1)\n",
        "  \n",
        "  val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    samplewise_center = 0,\n",
        "    validation_split = 0.1)\n",
        "  \n",
        "  test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    samplewise_center = 0)\n",
        "  \n",
        "  train_aug_dataset = train_datagen.flow_from_directory(\n",
        "    dir_train,\n",
        "    target_size = (img_dim,img_dim),\n",
        "    batch_size = batch,\n",
        "    classes = ['Amphibia', 'Animalia', 'Arachnida', 'Aves', 'Fungi', 'Insecta', 'Mammalia', 'Mollusca', 'Plantae', 'Reptilia'],\n",
        "    class_mode='categorical',\n",
        "    subset = 'training',\n",
        "    seed = seed)\n",
        "\n",
        "  train_dataset = val_datagen.flow_from_directory(\n",
        "    dir_train,\n",
        "    target_size = (img_dim,img_dim),\n",
        "    batch_size = batch,\n",
        "    classes = ['Amphibia', 'Animalia', 'Arachnida', 'Aves', 'Fungi', 'Insecta', 'Mammalia', 'Mollusca', 'Plantae', 'Reptilia'],\n",
        "    class_mode='categorical',\n",
        "    subset = 'training',\n",
        "    seed = seed)\n",
        "  \n",
        "  val_dataset = val_datagen.flow_from_directory(\n",
        "    dir_train,\n",
        "    target_size = (img_dim,img_dim),\n",
        "    batch_size = batch,\n",
        "    classes = ['Amphibia', 'Animalia', 'Arachnida', 'Aves', 'Fungi', 'Insecta', 'Mammalia', 'Mollusca', 'Plantae', 'Reptilia'],\n",
        "    class_mode='categorical',\n",
        "    subset = 'validation',\n",
        "    seed = seed)\n",
        "  \n",
        "  test_dataset = test_datagen.flow_from_directory(\n",
        "    dir_test,\n",
        "    targent_size = (img_dim,img_dim),\n",
        "    batch_size = batch,\n",
        "    classes = ['Amphibia', 'Animalia', 'Arachnida', 'Aves', 'Fungi', 'Insecta', 'Mammalia', 'Mollusca', 'Plantae', 'Reptilia'],\n",
        "    class_mode='categorical',\n",
        "    subset = None,\n",
        "    seed = seed\n",
        "  )\n",
        "  \n",
        "  return train_aug_dataset, train_dataset, val_dataset, test_datagen"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tS1dbW14N2Gq"
      },
      "source": [
        "#Do we need this?\n",
        "learn_rate = keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=1e-2,\n",
        "    decay_steps=1000,\n",
        "    decay_rate=0.9)\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzIoeqngVtLq"
      },
      "source": [
        "def CNN_wo_BN(filter_matrix, kernel_matrix, activation_matrix, fdropout, dense_no, learning_rate):\n",
        "\n",
        "  # Input layer\n",
        "  X_input = keras.Input(shape=(img_dim,img_dim,channel_no))\n",
        "\n",
        "  # Layer 1\n",
        "  X = Conv2D(filter_matrix[0], kernel_matrix[0])(X_input)\n",
        "  X = Activation(activation_matrix[0])(X)\n",
        "  X = MaxPooling2D(pool_size=(2, 2))(X)\n",
        "\n",
        "  # Layer 2\n",
        "  X = Conv2D(filter_matrix[1], kernel_matrix[1])(X)\n",
        "  X = Activation(activation_matrix[1])(X)\n",
        "  X = MaxPooling2D(pool_size=(2, 2))(X)\n",
        "\n",
        "  # Layer 3\n",
        "  X = Conv2D(filter_matrix[2], kernel_matrix[2])(X)\n",
        "  X = Activation(activation_matrix[2])(X)\n",
        "  X = MaxPooling2D(pool_size=(2, 2))(X)\n",
        "\n",
        "  # Layer 4\n",
        "  X = Conv2D(filter_matrix[3], kernel_matrix[3])(X)\n",
        "  X = Activation(activation_matrix[3])(X)\n",
        "  X = MaxPooling2D(pool_size=(2, 2))(X)\n",
        "\n",
        "  # Layer 5\n",
        "  X = Conv2D(filter_matrix[4], kernel_matrix[4])(X)\n",
        "  X = Activation(activation_matrix[4])(X)\n",
        "  X = MaxPooling2D(pool_size=(2, 2))(X)\n",
        "\n",
        "  X = Flatten()(X)\n",
        "  X = Dense(dense_no,activation=activation_matrix[5])(X)\n",
        "  X = Dropout(fdropout)(X)\n",
        "  X = Dense(10,activation='softmax')(X)\n",
        "  \n",
        "  model=Model(inputs=X_input,outputs=X)\n",
        "  model.compile(optimizer=Adam(learning_rate), loss='categorical_crossentropy',  metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvurXgaSfK8U"
      },
      "source": [
        "def CNN_w_BN(filter_matrix, kernel_matrix, activation_matrix, fdropout, dense_no, learning_rate):\n",
        "\n",
        "  # Input layer\n",
        "  X_input = keras.Input(shape=(img_dim,img_dim,channel_no))\n",
        "\n",
        "  # Layer 1\n",
        "  X = Conv2D(filter_matrix[0], kernel_matrix[0])(X_input)\n",
        "  X = BatchNormalization()(X)\n",
        "  X = Activation(activation_matrix[0])(X)\n",
        "  X = MaxPooling2D(pool_size=(2, 2))(X)\n",
        "\n",
        "  # Layer 2\n",
        "  X = Conv2D(filter_matrix[1], kernel_matrix[1])(X)\n",
        "  X = BatchNormalization()(X)\n",
        "  X = Activation(activation_matrix[1])(X)\n",
        "  X = MaxPooling2D(pool_size=(2, 2))(X)\n",
        "\n",
        "  # Layer 3\n",
        "  X = Conv2D(filter_matrix[2], kernel_matrix[2])(X)\n",
        "  X = BatchNormalization()(X)\n",
        "  X = Activation(activation_matrix[2])(X)\n",
        "  X = MaxPooling2D(pool_size=(2, 2))(X)\n",
        "\n",
        "  # Layer 4\n",
        "  X = Conv2D(filter_matrix[3], kernel_matrix[3])(X)\n",
        "  X = BatchNormalization()(X)\n",
        "  X = Activation(activation_matrix[3])(X)\n",
        "  X = MaxPooling2D(pool_size=(2, 2))(X)\n",
        "\n",
        "  # Layer 5\n",
        "  X = Conv2D(filter_matrix[4], kernel_matrix[4])(X)\n",
        "  X = BatchNormalization()(X)\n",
        "  X = Activation(activation_matrix[4])(X)\n",
        "  X = MaxPooling2D(pool_size=(2, 2))(X)\n",
        "\n",
        "  X = Flatten()(X)\n",
        "  X = Dense(dense_no,activation=activation_matrix[5])(X)\n",
        "  X = Dropout(fdropout)(X)\n",
        "  X = Dense(10,activation='softmax')(X)\n",
        "  \n",
        "  model=Model(inputs=X_input,outputs=X)\n",
        "  model.compile(optimizer=Adam(learning_rate), loss='categorical_crossentropy',  metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKPL9RF3Xrs9"
      },
      "source": [
        "def model_choose(filter_matrix, kernel_matrix, activation_matrix, dropout, dense_no, batch_norm, learning_rate):\n",
        "  # if filter_type == 'constant':\n",
        "  #   filter_matrix = [filter_start]*4\n",
        "  # elif filter_type == 'doubling':\n",
        "  #   filter_matrix = [highest_filter/16, highest_filter/8, highest_filter/4, highest_filter/2, highest_filter]\n",
        "  # elif filter_type == 'halving':\n",
        "  #   filter_matrix = [highest_filter, highest_filter/2, highest_filter/4, highest_filter/8, highest_filter/16]\n",
        "  # # wandb.log({\"Filters\": filter_matrix})\n",
        "  wandb.log({\"Filters\": filter_matrix})\n",
        "  if batch_norm == True:\n",
        "    model = CNN_w_BN(filter_matrix, kernel_matrix, activation_matrix, dropout, dense_no, learning_rate)\n",
        "  else:\n",
        "    model = CNN_wo_BN(filter_matrix, kernel_matrix, activation_matrix, dropout, dense_no, learning_rate)\n",
        "  \n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0fTjJp1c2SF"
      },
      "source": [
        "@tf.custom_gradient\n",
        "def GBRelu(x):\n",
        "  def gradient(dy):\n",
        "    grad = tf.cast(dy>0,\"float32\")*tf.cast(x>0, \"float32\")*dy\n",
        "    return  grad\n",
        "  return tf.nn.relu(x), gradient\n",
        "# Here model is the best model\n",
        "GBModel = Model(inputs = [model.inputs],outputs = [model.get_layer(index=8).output]) # Here the index is to be checked\n",
        "layer_dict = [layer for layer in gb_model.layers[1:] if hasattr(layer,'activation')]\n",
        "for layer in layer_dict:\n",
        "  if layer.activation == tf.keras.activations.relu:\n",
        "    layer.activation = GBRelu\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "  inputs = tf.cast(X_input, tf.float32)\n",
        "  tape.watch(inputs)\n",
        "  outputs = GBModel(inputs)\n",
        "\n",
        "grads = tape.gradient(outputs,inputs)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6V3TPqY4Bj_4"
      },
      "source": [
        "sweep_config = {\n",
        "    'method': 'grid'\n",
        "    }\n",
        "\n",
        "parameters_dict = {\n",
        "    'filter_matrix':{\n",
        "        'values': [0]\n",
        "      },\n",
        "    'kernel_matrix': {\n",
        "        'values': [0]\n",
        "      },\n",
        "    'activation_matrix': {\n",
        "        'values': [0]\n",
        "    }\n",
        "    'learn_rate': {\n",
        "        'values': [1e-3]\n",
        "      },\n",
        "    'epochs': {\n",
        "        'values': [5,10]\n",
        "      },\n",
        "    # 'batch_size': {\n",
        "    #     'values': [256]\n",
        "    #   },\n",
        "    'dropout': {\n",
        "        'values': [0.2]\n",
        "      },\n",
        "    'batch_normalization': {\n",
        "        'values': [True]\n",
        "      },\n",
        "    'dense_number': {\n",
        "          'values': [512]\n",
        "      },\n",
        "    'augmentation':{\n",
        "        'values' : [True]\n",
        "    }\n",
        "}\n",
        "sweep_config['parameters'] = parameters_dict\n",
        "pprint.pprint(sweep_config)\n",
        "\n",
        "def training_sweep(config=None):\n",
        "    with wandb.init(config=config):\n",
        "        config = wandb.config\n",
        "\n",
        "        F = fliters[config.filter_matrix]\n",
        "        K = kernels[config.kernel_matrix]\n",
        "        A = activations[config.activation_matrix]\n",
        "\n",
        "        model = model_choose(F, K, A, config.dropout, config.dense_number, config.batch_normalization, config.learn_rate)\n",
        "        if config.augmentation == True:\n",
        "          train = train_aug_dataset\n",
        "        else:\n",
        "          train = train_dataset\n",
        "\n",
        "        history = model.fit(train, \n",
        "                            epochs=config.epochs,\n",
        "                            validation_data = val,\n",
        "                            callbacks = callback\n",
        "                            )\n",
        "        wandb.log(history.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-wIWL35EhgC"
      },
      "source": [
        "global img_dim\n",
        "img_dim = 150\n",
        "\n",
        "global channel_no\n",
        "channel_no = 3 #3 for RGB images, 1 for greyscale\n",
        "\n",
        "global batch\n",
        "batch = 256\n",
        "\n",
        "global filters\n",
        "filters = [[64,128,256,512,1024]]\n",
        "\n",
        "global kernels\n",
        "kernels = [[(3,3)]*5]\n",
        "\n",
        "global activations\n",
        "activations = [['relu']*6]\n",
        "\n",
        "global F, global K, global A\n",
        "\n",
        "global train_aug_dataset, global train_dataset, global val_dataset, global test_datagen\n",
        "train_aug_dataset, train_dataset, val_dataset, test_datagen = load_data('/content/drive/MyDrive/inaturalist_12K/train', '/content/drive/MyDrive/inaturalist_12K/val', batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Agmt-aMLNOFu"
      },
      "source": [
        "sweep_id = wandb.sweep(sweep_config, project=\"CS6910-assg2\")\n",
        "wandb.agent(sweep_id, training_sweep)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}