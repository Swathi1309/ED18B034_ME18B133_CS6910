{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Swathi1309/ED18B034_ME18B133_CS6910/blob/main/Assignment2/Assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHaZ82DHnxOY"
      },
      "source": [
        "# Convolutional Neural Networks : Training from scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITq4YEA7oN6C"
      },
      "source": [
        "# Initial setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwpC4SmUV2Am"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv1D,Conv2D, BatchNormalization, Dropout, Activation, Softmax, MaxPooling2D\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import random\n",
        "import pprint\n",
        "\n",
        "from  matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zc-ihRCxs9Db"
      },
      "source": [
        "The dataset in our case was uploaded on google drive. To access the same, we have to mount drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qDInjFlMBk3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "classes = ['Amphibia', 'Animalia', 'Arachnida', 'Aves', 'Fungi', 'Insecta', 'Mammalia', 'Mollusca', 'Plantae', 'Reptilia']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gXqxZPXD-ZK"
      },
      "source": [
        "!pip install wandb\n",
        "!wandb login\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "wandb.init(project=\"CS6910-assg2\", entity=\"swathi\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kqvf806cpcHh"
      },
      "source": [
        "# Function to load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OM-zwdYSo1ap"
      },
      "source": [
        "def load_data(dir_train, dir_test, batch):\n",
        "  \n",
        "  seed = 42\n",
        "  \n",
        "  train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    samplewise_center = 0,\n",
        "    horizontal_flip = True,\n",
        "    rotation_range = 30,\n",
        "    validation_split = 0.1)\n",
        "  \n",
        "  val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    samplewise_center = 0,\n",
        "    validation_split = 0.1)\n",
        "  \n",
        "  test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    samplewise_center = 0)\n",
        "  \n",
        "  train_aug_dataset = train_datagen.flow_from_directory(\n",
        "    dir_train,\n",
        "    target_size = (img_dim,img_dim),\n",
        "    batch_size = batch,\n",
        "    classes = ['Amphibia', 'Animalia', 'Arachnida', 'Aves', 'Fungi', 'Insecta', 'Mammalia', 'Mollusca', 'Plantae', 'Reptilia'],\n",
        "    class_mode='categorical',\n",
        "    subset = 'training',\n",
        "    seed = seed)\n",
        "\n",
        "  train_dataset = val_datagen.flow_from_directory(\n",
        "    dir_train,\n",
        "    target_size = (img_dim,img_dim),\n",
        "    batch_size = batch,\n",
        "    classes = ['Amphibia', 'Animalia', 'Arachnida', 'Aves', 'Fungi', 'Insecta', 'Mammalia', 'Mollusca', 'Plantae', 'Reptilia'],\n",
        "    class_mode='categorical',\n",
        "    subset = 'training',\n",
        "    seed = seed)\n",
        "  \n",
        "  val_dataset = val_datagen.flow_from_directory(\n",
        "    dir_train,\n",
        "    target_size = (img_dim,img_dim),\n",
        "    batch_size = batch,\n",
        "    classes = ['Amphibia', 'Animalia', 'Arachnida', 'Aves', 'Fungi', 'Insecta', 'Mammalia', 'Mollusca', 'Plantae', 'Reptilia'],\n",
        "    class_mode='categorical',\n",
        "    subset = 'validation',\n",
        "    seed = seed)\n",
        "  \n",
        "  test_dataset = test_datagen.flow_from_directory(\n",
        "    dir_test,\n",
        "    target_size = (img_dim,img_dim),\n",
        "    batch_size = batch,\n",
        "    classes = ['Amphibia', 'Animalia', 'Arachnida', 'Aves', 'Fungi', 'Insecta', 'Mammalia', 'Mollusca', 'Plantae', 'Reptilia'],\n",
        "    class_mode='categorical',\n",
        "    subset = None,\n",
        "    seed = seed\n",
        "  )\n",
        "  \n",
        "  return train_aug_dataset, train_dataset, val_dataset, test_dataset"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGFEwtf1pj9k"
      },
      "source": [
        "# Functions to define models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzIoeqngVtLq"
      },
      "source": [
        "# Without Batch Normalization\n",
        "def CNN_wo_BN(filter_matrix, kernel_matrix, activation_matrix, fdropout, dense_no, learning_rate):\n",
        "  # Input layer\n",
        "  X_input = keras.Input(shape=(img_dim,img_dim,channel_no))\n",
        "  # Layer 1\n",
        "  X = Conv2D(filter_matrix[0], kernel_matrix[0])(X_input)\n",
        "  X = Activation(activation_matrix[0])(X)\n",
        "  X = MaxPooling2D(pool_size=(2, 2))(X)\n",
        "  # Layer 2\n",
        "  X = Conv2D(filter_matrix[1], kernel_matrix[1])(X)\n",
        "  X = Activation(activation_matrix[1])(X)\n",
        "  X = MaxPooling2D(pool_size=(2, 2))(X)\n",
        "  # Layer 3\n",
        "  X = Conv2D(filter_matrix[2], kernel_matrix[2])(X)\n",
        "  X = Activation(activation_matrix[2])(X)\n",
        "  X = MaxPooling2D(pool_size=(2, 2))(X)\n",
        "  # Layer 4\n",
        "  X = Conv2D(filter_matrix[3], kernel_matrix[3])(X)\n",
        "  X = Activation(activation_matrix[3])(X)\n",
        "  X = MaxPooling2D(pool_size=(2, 2))(X)\n",
        "  # Layer 5\n",
        "  X = Conv2D(filter_matrix[4], kernel_matrix[4])(X)\n",
        "  X = Activation(activation_matrix[4])(X)\n",
        "  X = MaxPooling2D(pool_size=(2, 2))(X)\n",
        "  # Dense layers\n",
        "  X = Flatten()(X)\n",
        "  X = Dense(dense_no,activation=activation_matrix[5])(X)\n",
        "  X = Dropout(fdropout)(X)\n",
        "  X = Dense(10,activation='softmax')(X)\n",
        "  model=Model(inputs=X_input,outputs=X)\n",
        "  model.compile(optimizer=Adam(learning_rate), loss='categorical_crossentropy',  metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "# With Batch Normalization\n",
        "def CNN_w_BN(filter_matrix, kernel_matrix, activation_matrix, fdropout, dense_no, learning_rate):\n",
        "  # Input layer\n",
        "  X_input = keras.Input(shape=(img_dim,img_dim,channel_no))\n",
        "  # Layer 1\n",
        "  X = Conv2D(filter_matrix[0], kernel_matrix[0])(X_input)\n",
        "  X = BatchNormalization()(X)\n",
        "  X = Activation(activation_matrix[0])(X)\n",
        "  X = MaxPooling2D(pool_size=(2, 2))(X)\n",
        "  # Layer 2\n",
        "  X = Conv2D(filter_matrix[1], kernel_matrix[1])(X)\n",
        "  X = BatchNormalization()(X)\n",
        "  X = Activation(activation_matrix[1])(X)\n",
        "  X = MaxPooling2D(pool_size=(2, 2))(X)\n",
        "  # Layer 3\n",
        "  X = Conv2D(filter_matrix[2], kernel_matrix[2])(X)\n",
        "  X = BatchNormalization()(X)\n",
        "  X = Activation(activation_matrix[2])(X)\n",
        "  X = MaxPooling2D(pool_size=(2, 2))(X)\n",
        "  # Layer 4\n",
        "  X = Conv2D(filter_matrix[3], kernel_matrix[3])(X)\n",
        "  X = BatchNormalization()(X)\n",
        "  X = Activation(activation_matrix[3])(X)\n",
        "  X = MaxPooling2D(pool_size=(2, 2))(X)\n",
        "  # Layer 5\n",
        "  X = Conv2D(filter_matrix[4], kernel_matrix[4])(X)\n",
        "  X = BatchNormalization()(X)\n",
        "  X = Activation(activation_matrix[4])(X)\n",
        "  X = MaxPooling2D(pool_size=(2, 2))(X)\n",
        "  # Dense layers\n",
        "  X = Flatten()(X)\n",
        "  X = Dense(dense_no,activation=activation_matrix[5])(X)\n",
        "  X = Dropout(fdropout)(X)\n",
        "  X = Dense(10,activation='softmax')(X)\n",
        "  model=Model(inputs=X_input,outputs=X)\n",
        "  model.compile(optimizer=Adam(learning_rate), loss='categorical_crossentropy',  metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "\n",
        "def model_choose(filter_matrix, kernel_matrix, activation_matrix, dropout, dense_no, batch_norm, learning_rate):\n",
        "  wandb.log({\"Filters\": filter_matrix})\n",
        "  if batch_norm == True:\n",
        "    model = CNN_w_BN(filter_matrix, kernel_matrix, activation_matrix, dropout, dense_no, learning_rate)\n",
        "  else:\n",
        "    model = CNN_wo_BN(filter_matrix, kernel_matrix, activation_matrix, dropout, dense_no, learning_rate)\n",
        "  return model"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDsAfw3fp-qw"
      },
      "source": [
        "# Defining parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-wIWL35EhgC"
      },
      "source": [
        "global img_dim\n",
        "img_dim = 200\n",
        "\n",
        "global channel_no\n",
        "channel_no = 3\n",
        "#3 for RGB images, 1 for greyscale\n",
        "\n",
        "global batch\n",
        "batch = 128\n",
        "\n",
        "global filters\n",
        "filters = [[64,128,256,512,512],[64,128,256,256,512],[128,256,256,512,512],[96,128,256,512,512]]\n",
        "\n",
        "global kernels\n",
        "kernels = [[(3,3)]*5, [(5,5)]*5]\n",
        "\n",
        "global activations\n",
        "activations = [['relu']*6]\n",
        "\n",
        "global F, K, A\n",
        "\n",
        "global train_aug_dataset, train_dataset, val_dataset, test_datagen\n",
        "train_aug_dataset, train_dataset, val_dataset, test_dataset = load_data('/content/drive/MyDrive/inaturalist_12K/train', '/content/drive/MyDrive/inaturalist_12K/val', batch)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NTCxBy3qMOt"
      },
      "source": [
        "# Hyperparameter sweeps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6V3TPqY4Bj_4"
      },
      "source": [
        "sweep_config = {\n",
        "    'method': 'grid'\n",
        "    }\n",
        "\n",
        "parameters_dict = {\n",
        "    'filter_matrix':{\n",
        "        'values': [3] # 0,1,2,3\n",
        "      },\n",
        "    'kernel_matrix': {\n",
        "        'values': [1] # 0,1\n",
        "      },\n",
        "    'activation_matrix': {\n",
        "        'values': [0]\n",
        "      },\n",
        "    'learn_rate': {\n",
        "        'values': [1e-3] # 1e-3, 0.3\n",
        "      },\n",
        "    'epochs': {\n",
        "        'values': [40]\n",
        "      },\n",
        "    'dropout': {\n",
        "        'values': [0.5] # 0.2, 0.5\n",
        "      },\n",
        "    'batch_normalization': {\n",
        "        'values': [False] # True, False\n",
        "      },\n",
        "    'dense_number': {\n",
        "          'values': [512]\n",
        "      },\n",
        "    'augmentation':{\n",
        "        'values' : [True] # True, False\n",
        "      }\n",
        "}\n",
        "sweep_config['parameters'] = parameters_dict\n",
        "pprint.pprint(sweep_config)\n",
        "\n",
        "def training_sweep(config=None):\n",
        "    with wandb.init(config=config):\n",
        "        config = wandb.config\n",
        "\n",
        "        F = filters[config.filter_matrix]\n",
        "        K = kernels[config.kernel_matrix]\n",
        "        A = activations[config.activation_matrix]\n",
        "\n",
        "        model = model_choose(F, K, A, config.dropout, config.dense_number, config.batch_normalization, config.learn_rate)\n",
        "        if config.augmentation == True:\n",
        "          train = train_aug_dataset\n",
        "        else:\n",
        "          train = train_dataset\n",
        "\n",
        "        history = model.fit(train, \n",
        "                            epochs=config.epochs,\n",
        "                            validation_data = val_dataset,\n",
        "                            callbacks = [WandbCallback(data_type='image', labels = classes)]\n",
        "                            )\n",
        "        ### On the best model only: \n",
        "        # model.save('/content/drive/MyDrive/Assgn2model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Agmt-aMLNOFu"
      },
      "source": [
        "sweep_id = wandb.sweep(sweep_config, project=\"CS6910-assg2\")\n",
        "wandb.agent(sweep_id, training_sweep)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcWTnlphrDxq"
      },
      "source": [
        "# Results on test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEUM2xb7tXew"
      },
      "source": [
        "To get the accuracy on the test dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzXDFxuebk-z"
      },
      "source": [
        "model = keras.models.load_model('/content/drive/MyDrive/Assgn2model')\n",
        "model.summary()\n",
        "result = model.evaluate(test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeNGBEXDtbEN"
      },
      "source": [
        "Two ImageGenerator iterators are taken to plot random images, instead of the entire test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojQWwBCdrQcL"
      },
      "source": [
        "(x,y) = test_dataset.next()\n",
        "(x2,y2) = test_dataset.next()\n",
        "predictions1 = model.predict(x)\n",
        "predictions2 = model.predict(x2)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tus5zsASrTXY"
      },
      "source": [
        "fig, a = plt.subplots(3, 10, figsize=(30,30))\n",
        "for i in range(0,3):\n",
        "  for j in range(0,10):\n",
        "    rand = random.randint(0,batch-1)\n",
        "    if j%2 == 0:\n",
        "      a[i][j].imshow(x[rand])\n",
        "      one_hot=y[rand]\n",
        "      pred = np.argmax(predictions[rand])\n",
        "    else:\n",
        "      a[i][j].imshow(x2[rand])\n",
        "      one_hot=y2[rand]\n",
        "      pred = np.argmax(predictions2[rand])\n",
        "    for k in range(0,10):\n",
        "      if one_hot[k]==1:\n",
        "        name = classes[k]\n",
        "    title = name + \"(predicted:\" + classes[pred] + \")\"\n",
        "    if name == classes[pred]:\n",
        "      col = 'g'\n",
        "    else:\n",
        "      col = 'r'\n",
        "    a[i][j].set_title(title, color = col)\n",
        "fig.tight_layout(pad = 0, h_pad = -100)\n",
        "plt.savefig('/content/drive/MyDrive/Best_model_output.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-J0bb9freIr"
      },
      "source": [
        "# Visualising filters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhnRZgFhtoDD"
      },
      "source": [
        "Creating a new model upto the first layer, and predicting outputs on one random image from test dataset. These outputs are the filters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FV0J4WTUrajI"
      },
      "source": [
        "NewModel = Model(inputs = [model.inputs],outputs = [model.get_layer(index=1).output])\n",
        "NewModel.summary()\n",
        "\n",
        "num = random.randint(0,127)\n",
        "input = np.expand_dims(x[num], axis = 0)\n",
        "outputs = NewModel.predict(input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55LvcM2Bt14J"
      },
      "source": [
        "To see the original image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFWgHUtKrqvi"
      },
      "source": [
        "plt.imshow(x[num])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9cVFgtIt4wZ"
      },
      "source": [
        "To view the filters as a grid:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xb-rytlrqUN"
      },
      "source": [
        "fig, a = plt.subplots(12, 8, figsize=(20,20))\n",
        "for i in range(0,12):\n",
        "  for j in range(0,8):\n",
        "    a[i][j].imshow(outputs[0,:,:,12*j+i], cmap='gray')\n",
        "fig.tight_layout(pad = 0, h_pad =0)\n",
        "plt.savefig('/content/drive/MyDrive/A_4_c.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmKnzZhorzYa"
      },
      "source": [
        "# Guided Backpropagation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41Sub9-St-jC"
      },
      "source": [
        "For a random input from test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vmu05iglK5-d"
      },
      "source": [
        "(x,y) = test_dataset.next()\n",
        "num = random.randint(0,127)\n",
        "x_backprop = np.expand_dims(x[num],axis=0)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aJxYNOPuPWh"
      },
      "source": [
        "On the best model, and layer index 13 (5th convolutional layer):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0fTjJp1c2SF"
      },
      "source": [
        "@tf.custom_gradient\n",
        "def GBRelu(x):\n",
        "  def gradient(dy):\n",
        "    grad = tf.cast(dy>0,\"float32\")*tf.cast(x>0, \"float32\")*dy\n",
        "    return  grad\n",
        "  return tf.nn.relu(x), gradient\n",
        "\n",
        "GBModel = Model(inputs = [model.inputs],outputs = [model.get_layer(index=13).output])\n",
        "layer_dict = [layer for layer in GBModel.layers[1:] if hasattr(layer,'activation')]\n",
        "for layer in layer_dict:\n",
        "  if layer.activation == tf.keras.activations.relu:\n",
        "    layer.activation = GBRelu"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeKvNAS8V532"
      },
      "source": [
        "grad_list=[]\n",
        "for i in range(0,10):\n",
        "  with tf.GradientTape(persistent=True) as tape:\n",
        "    inputs = tf.Variable(tf.cast(x_backprop, tf.float32))\n",
        "    outputs = GBModel(inputs)\n",
        "    new = np.zeros((1,8,8,512))\n",
        "    rand = np.random.randint(0,511)\n",
        "    new[:,:,:,rand] = np.ones((1,8,8))\n",
        "    outputs = outputs*new\n",
        "  grads = tape.gradient(outputs,inputs)[0]\n",
        "  grad_list.append(grads)\n",
        "  del grads"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6ns3C6FuWdj"
      },
      "source": [
        "Visualizing the original image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfDmt-TxhBqy"
      },
      "source": [
        "plt.imshow(x[num])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HntkHpYiuY19"
      },
      "source": [
        "Plotting the result of guided backpropagation for ten random neurons"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_yOpkBcMHaZ"
      },
      "source": [
        "fig, a = plt.subplots(1, 10, figsize=(30,30))\n",
        "for i in range(0,10):\n",
        "  a[i].imshow(np.array(grad_list[i])*255)\n",
        "plt.savefig ('/content/drive/MyDrive/GuidedBackprop.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
